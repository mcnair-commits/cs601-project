{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dbff71d-1ed4-41e8-842e-430cd81f1c20",
   "metadata": {},
   "source": [
    "Kelton McNair - 992018683\n",
    "CS 601 - Machine Learning\n",
    "Spring Semester Project 2025\n",
    "Dr. Afshar\n",
    "Random Forest Classifier\n",
    "Dataset: Adult Or letter-recognition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93a9f424-5098-4214-beb8-afe37b923c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ucimlrepo\n",
    "\n",
    "# from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# # fetch dataset \n",
    "# adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "# X = adult.data.features \n",
    "# y = adult.data.targets \n",
    "  \n",
    "# # metadata \n",
    "# print(adult.metadata) \n",
    "  \n",
    "# # variable information \n",
    "# print(adult.variables) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff9d4bab-68b9-42f7-b2b1-040f36af3198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# # fetch dataset \n",
    "# letter_recognition = fetch_ucirepo(id=59) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "# X = letter_recognition.data.features \n",
    "# y = letter_recognition.data.targets \n",
    "  \n",
    "# # metadata \n",
    "# print(letter_recognition.metadata) \n",
    "  \n",
    "# # variable information \n",
    "# print(letter_recognition.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18976bf9-2f7e-4092-9cb1-1cc1de604d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#not sure what all I need for comparative evaluation sklearn model yet\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import default_rng\n",
    "\n",
    "#hpyer parameters\n",
    "label_col_name = \"income\"\n",
    "num_trees_in_forest = 110\n",
    "depth_threshold = 10 #32560 samples / 2 (10 times) = 32\n",
    "# we could use a for loop to calc this based on sample size, and pass that to the two below \n",
    "split_leaf_minimum = 32\n",
    "split_node_min_samples = (split_leaf_minimum * 2) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b1a78a4-4025-4938-8d47-95ef80c82113",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"adult/adult.data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fefd73ed-a649-44ad-a4d4-e6a72d9505a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_col_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0721cf4-fcf1-4c24-a26d-626da02e65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = extracted_col_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72848efb-24d7-4c0d-91f3-27caa31ea87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "1   38            Private  215646     HS-grad              9   \n",
       "2   53            Private  234721        11th              7   \n",
       "3   28            Private  338409   Bachelors             13   \n",
       "4   37            Private  284582     Masters             14   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "1             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "2   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "3   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "4   Married-civ-spouse     Exec-managerial            Wife   White   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0             0             0              13   United-States   <=50K  \n",
       "1             0             0              40   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40            Cuba   <=50K  \n",
       "4             0             0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce56c6d6-1cf1-4243-9e9a-39ce0459e3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age      workclass  fnlwgt    education  education-num  \\\n",
       "32555   27        Private  257302   Assoc-acdm             12   \n",
       "32556   40        Private  154374      HS-grad              9   \n",
       "32557   58        Private  151910      HS-grad              9   \n",
       "32558   22        Private  201490      HS-grad              9   \n",
       "32559   52   Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation relationship    race      sex  \\\n",
       "32555   Married-civ-spouse        Tech-support         Wife   White   Female   \n",
       "32556   Married-civ-spouse   Machine-op-inspct      Husband   White     Male   \n",
       "32557              Widowed        Adm-clerical    Unmarried   White   Female   \n",
       "32558        Never-married        Adm-clerical    Own-child   White     Male   \n",
       "32559   Married-civ-spouse     Exec-managerial         Wife   White   Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "32555             0             0              38   United-States   <=50K  \n",
       "32556             0             0              40   United-States    >50K  \n",
       "32557             0             0              40   United-States   <=50K  \n",
       "32558             0             0              20   United-States   <=50K  \n",
       "32559         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59fad8ef-4763-48f0-8c9e-84c7e20ead28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0  False      False   False      False          False           False   \n",
       "1  False      False   False      False          False           False   \n",
       "2  False      False   False      False          False           False   \n",
       "3  False      False   False      False          False           False   \n",
       "4  False      False   False      False          False           False   \n",
       "\n",
       "   occupation  relationship   race    sex  capital-gain  capital-loss  \\\n",
       "0       False         False  False  False         False         False   \n",
       "1       False         False  False  False         False         False   \n",
       "2       False         False  False  False         False         False   \n",
       "3       False         False  False  False         False         False   \n",
       "4       False         False  False  False         False         False   \n",
       "\n",
       "   hours-per-week  native-country  income  \n",
       "0           False           False   False  \n",
       "1           False           False   False  \n",
       "2           False           False   False  \n",
       "3           False           False   False  \n",
       "4           False           False   False  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0854f978-62cb-43c3-95af-675943256355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32560 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0      False      False   False      False          False           False   \n",
       "1      False      False   False      False          False           False   \n",
       "2      False      False   False      False          False           False   \n",
       "3      False      False   False      False          False           False   \n",
       "4      False      False   False      False          False           False   \n",
       "...      ...        ...     ...        ...            ...             ...   \n",
       "32555  False      False   False      False          False           False   \n",
       "32556  False      False   False      False          False           False   \n",
       "32557  False      False   False      False          False           False   \n",
       "32558  False      False   False      False          False           False   \n",
       "32559  False      False   False      False          False           False   \n",
       "\n",
       "       occupation  relationship   race    sex  capital-gain  capital-loss  \\\n",
       "0           False         False  False  False         False         False   \n",
       "1           False         False  False  False         False         False   \n",
       "2           False         False  False  False         False         False   \n",
       "3           False         False  False  False         False         False   \n",
       "4           False         False  False  False         False         False   \n",
       "...           ...           ...    ...    ...           ...           ...   \n",
       "32555       False         False  False  False         False         False   \n",
       "32556       False         False  False  False         False         False   \n",
       "32557       False         False  False  False         False         False   \n",
       "32558       False         False  False  False         False         False   \n",
       "32559       False         False  False  False         False         False   \n",
       "\n",
       "       hours-per-week  native-country  income  \n",
       "0               False           False   False  \n",
       "1               False           False   False  \n",
       "2               False           False   False  \n",
       "3               False           False   False  \n",
       "4               False           False   False  \n",
       "...               ...             ...     ...  \n",
       "32555           False           False   False  \n",
       "32556           False           False   False  \n",
       "32557           False           False   False  \n",
       "32558           False           False   False  \n",
       "32559           False           False   False  \n",
       "\n",
       "[32560 rows x 15 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e6260ea-6f97-4b0f-a472-eeb089d6ff76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education-num     0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours-per-week    0\n",
       "native-country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "006675ea-0a79-429f-8a38-1c1227370a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [age, workclass, fnlwgt, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.age.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e33319c5-e99a-48a1-8f32-b8ed3aa95b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "36    898\n",
       "31    888\n",
       "34    886\n",
       "23    877\n",
       "35    876\n",
       "     ... \n",
       "83      6\n",
       "88      3\n",
       "85      3\n",
       "86      1\n",
       "87      1\n",
       "Name: count, Length: 73, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if rows with missing values are > x% we need to do something with them\n",
    "# if rows with missing values are <x% we drop ##\n",
    "# data.dropna(how=\"any\").shape --- this would drop anyrow with a single missing values # how=\"all\" would be all cols missing\n",
    "# subset = dropna(subset = ['x', 'y'], how='any').shape would only consider the subset of specific columns\n",
    "\n",
    "#filling missing values:\n",
    "data['age'].value_counts() # filtered from greatest to least value occurence (dropna=False) as a parameter would should how many missing \n",
    "\n",
    "#fillna(value, inplace) to change missing values to the value specified\n",
    "#can you call a function, like knn as the value? \n",
    "\n",
    "\n",
    "\n",
    "# inplace would commit the action to the dataframe , make the change in place\n",
    "# what is x?\n",
    "# what do we do with those rows if %>x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3734b012-b7d0-4e28-883b-6c3e51b91ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/aiskunks/categorical-data-encoding-techniques-d6296697a40f\n",
    "# lets try the sklearn.preprocessing ordinal encoder first\n",
    "# doesnt look like we need to use 1-hot and it may adversaly affect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19873846-8577-4ef6-817c-256e845e034b",
   "metadata": {},
   "source": [
    "In AI class we converted to a \"one-hot vector\"\n",
    "\n",
    "# Convert y into one-hot vector\n",
    "def convert_y(y, num_output):\n",
    "    result = torch.zeros(y.size(0), num_output)\n",
    "    for i in range(y.size(0)):\n",
    "        result[i, y[i]] = 1\n",
    "    return result\n",
    "\n",
    "\n",
    "One hot is one method for data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "628075d1-8ab2-4a6b-8859-78836827eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_information (num_samples):\n",
    "    depth_counter = 0\n",
    "    resulting = 15\n",
    "    calcd_resulting = num_samples\n",
    "    while (calcd_resulting > resulting):\n",
    "        depth_counter+=1\n",
    "        calcd_resulting = np.ceil(calcd_resulting / 2) #int division \"//\" would do floor\n",
    "\n",
    "    return depth_counter, calcd_resulting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76db7453-dd52-444c-8098-3eaeefa3b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hpyer parameters\n",
    "label_col_name = \"income\"\n",
    "num_trees_in_forest = 110\n",
    "\n",
    "depth_threshold = 10 #32560 samples / 2 (10 times) = 32\n",
    "# we could use a for loop to calc this based on sample size, and pass that to the two below \n",
    "split_leaf_minimum = 32\n",
    "\n",
    "depth_threshold, split_leaf_minimum = sample_information(data.shape[0])\n",
    "\n",
    "split_node_min_samples = (split_leaf_minimum * 2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53090540-862b-47bb-8143-b012f9bf0d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 8.0 17.0\n"
     ]
    }
   ],
   "source": [
    "print(depth_threshold, split_leaf_minimum, split_node_min_samples)\n",
    "# what is a good depth? what is a good number of min samples to split and per leaf values?\n",
    "# i think i read 6-7 depth is a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8a4087e-576d-49f8-b95f-fd3e0dee2aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32560, 15)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "718212c2-6ad6-4102-bb68-213d409c2d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "1   38            Private  215646     HS-grad              9   \n",
       "2   53            Private  234721        11th              7   \n",
       "3   28            Private  338409   Bachelors             13   \n",
       "4   37            Private  284582     Masters             14   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "1             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "2   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "3   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "4   Married-civ-spouse     Exec-managerial            Wife   White   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0             0             0              13   United-States   <=50K  \n",
       "1             0             0              40   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40            Cuba   <=50K  \n",
       "4             0             0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "# Need to add column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3eeceae-649e-48bb-a473-3fdf00b9e45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32560, 15)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "865d2fbd-b65d-4771-89c8-37de3a7453e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "1   38            Private  215646     HS-grad              9   \n",
       "2   53            Private  234721        11th              7   \n",
       "3   28            Private  338409   Bachelors             13   \n",
       "4   37            Private  284582     Masters             14   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "1             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "2   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "3   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "4   Married-civ-spouse     Exec-managerial            Wife   White   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0             0             0              13   United-States   <=50K  \n",
       "1             0             0              40   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40            Cuba   <=50K  \n",
       "4             0             0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c545fd9f-7f93-4324-8f4d-b467cdbff098",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"adult/adult.test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "462eb049-84c1-4d55-8652-1f7e4e73f3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16281, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2e1d65b-e75e-46f2-ba3b-b5fc4bf74f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>|1x3 Cross validator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <th>Private</th>\n",
       "      <th>226802</th>\n",
       "      <th>11th</th>\n",
       "      <th>7</th>\n",
       "      <th>Never-married</th>\n",
       "      <th>Machine-op-inspct</th>\n",
       "      <th>Own-child</th>\n",
       "      <th>Black</th>\n",
       "      <th>Male</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>40</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <th>Private</th>\n",
       "      <th>89814</th>\n",
       "      <th>HS-grad</th>\n",
       "      <th>9</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Farming-fishing</th>\n",
       "      <th>Husband</th>\n",
       "      <th>White</th>\n",
       "      <th>Male</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>50</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>336951</th>\n",
       "      <th>Assoc-acdm</th>\n",
       "      <th>12</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Protective-serv</th>\n",
       "      <th>Husband</th>\n",
       "      <th>White</th>\n",
       "      <th>Male</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>40</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <th>Private</th>\n",
       "      <th>160323</th>\n",
       "      <th>Some-college</th>\n",
       "      <th>10</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Machine-op-inspct</th>\n",
       "      <th>Husband</th>\n",
       "      <th>Black</th>\n",
       "      <th>Male</th>\n",
       "      <th>7688</th>\n",
       "      <th>0</th>\n",
       "      <th>40</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>?</th>\n",
       "      <th>103497</th>\n",
       "      <th>Some-college</th>\n",
       "      <th>10</th>\n",
       "      <th>Never-married</th>\n",
       "      <th>?</th>\n",
       "      <th>Own-child</th>\n",
       "      <th>White</th>\n",
       "      <th>Female</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>30</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                        |1x3 Cross validator\n",
       "25 Private   226802 11th         7  Never-married      Machine-op-inspct Own-child Black Male   0    0 40 United-States               <=50K.\n",
       "38 Private   89814  HS-grad      9  Married-civ-spouse Farming-fishing   Husband   White Male   0    0 50 United-States               <=50K.\n",
       "28 Local-gov 336951 Assoc-acdm   12 Married-civ-spouse Protective-serv   Husband   White Male   0    0 40 United-States                >50K.\n",
       "44 Private   160323 Some-college 10 Married-civ-spouse Machine-op-inspct Husband   Black Male   7688 0 40 United-States                >50K.\n",
       "18 ?         103497 Some-college 10 Never-married      ?                 Own-child White Female 0    0 30 United-States               <=50K."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adec5f9f-d96c-48fb-8e5c-8c3c9bde1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not work, not a csv names = pd.read_csv(\"adult/adult.names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a536a8d-c271-4dd3-99b6-895a30b5e9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| This data was extracted from the census bureau database found at\n",
      "| http://www.census.gov/ftp/pub/DES/www/welcome.html\n",
      "| Donor: Ronny Kohavi and Barry Becker,\n",
      "|        Data Mining and Visualization\n",
      "|        Silicon Graphics.\n",
      "|        e-mail: ronnyk@sgi.com for questions.\n",
      "| Split into train-test using MLC++ GenCVFiles (2/3, 1/3 random).\n",
      "| 48842 instances, mix of continuous and discrete    (train=32561, test=16281)\n",
      "| 45222 if instances with unknown values are removed (train=30162, test=15060)\n",
      "| Duplicate or conflicting instances : 6\n",
      "| Class probabilities for adult.all file\n",
      "| Probability for the label '>50K'  : 23.93% / 24.78% (without unknowns)\n",
      "| Probability for the label '<=50K' : 76.07% / 75.22% (without unknowns)\n",
      "|\n",
      "| Extraction was done by Barry Becker from the 1994 Census database.  A set of\n",
      "|   reasonably clean records was extracted using the following conditions:\n",
      "|   ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
      "|\n",
      "| Prediction task is to determine whether a person makes over 50K\n",
      "| a year.\n",
      "|\n",
      "| First cited in:\n",
      "| @inproceedings{kohavi-nbtree,\n",
      "|    author={Ron Kohavi},\n",
      "|    title={Scaling Up the Accuracy of Naive-Bayes Classifiers: a\n",
      "|           Decision-Tree Hybrid},\n",
      "|    booktitle={Proceedings of the Second International Conference on\n",
      "|               Knowledge Discovery and Data Mining},\n",
      "|    year = 1996,\n",
      "|    pages={to appear}}\n",
      "|\n",
      "| Error Accuracy reported as follows, after removal of unknowns from\n",
      "|    train/test sets):\n",
      "|    C4.5       : 84.46+-0.30\n",
      "|    Naive-Bayes: 83.88+-0.30\n",
      "|    NBTree     : 85.90+-0.28\n",
      "|\n",
      "|\n",
      "| Following algorithms were later run with the following error rates,\n",
      "|    all after removal of unknowns and using the original train/test split.\n",
      "|    All these numbers are straight runs using MLC++ with default values.\n",
      "|\n",
      "|    Algorithm               Error\n",
      "| -- ----------------        -----\n",
      "| 1  C4.5                    15.54\n",
      "| 2  C4.5-auto               14.46\n",
      "| 3  C4.5 rules              14.94\n",
      "| 4  Voted ID3 (0.6)         15.64\n",
      "| 5  Voted ID3 (0.8)         16.47\n",
      "| 6  T2                      16.84\n",
      "| 7  1R                      19.54\n",
      "| 8  NBTree                  14.10\n",
      "| 9  CN2                     16.00\n",
      "| 10 HOODG                   14.82\n",
      "| 11 FSS Naive Bayes         14.05\n",
      "| 12 IDTM (Decision table)   14.46\n",
      "| 13 Naive-Bayes             16.12\n",
      "| 14 Nearest-neighbor (1)    21.42\n",
      "| 15 Nearest-neighbor (3)    20.35\n",
      "| 16 OC1                     15.04\n",
      "| 17 Pebls                   Crashed.  Unknown why (bounds WERE increased)\n",
      "|\n",
      "| Conversion of original data as follows:\n",
      "| 1. Discretized agrossincome into two ranges with threshold 50,000.\n",
      "| 2. Convert U.S. to US to avoid periods.\n",
      "| 3. Convert Unknown to \"?\"\n",
      "| 4. Run MLC++ GenCVFiles to generate data,test.\n",
      "|\n",
      "| Description of fnlwgt (final weight)\n",
      "|\n",
      "| The weights on the CPS files are controlled to independent estimates of the\n",
      "| civilian noninstitutional population of the US.  These are prepared monthly\n",
      "| for us by Population Division here at the Census Bureau.  We use 3 sets of\n",
      "| controls.\n",
      "|  These are:\n",
      "|          1.  A single cell estimate of the population 16+ for each state.\n",
      "|          2.  Controls for Hispanic Origin by age and sex.\n",
      "|          3.  Controls by Race, age and sex.\n",
      "|\n",
      "| We use all three sets of controls in our weighting program and \"rake\" through\n",
      "| them 6 times so that by the end we come back to all the controls we used.\n",
      "|\n",
      "| The term estimate refers to population totals derived from CPS by creating\n",
      "| \"weighted tallies\" of any specified socio-economic characteristics of the\n",
      "| population.\n",
      "|\n",
      "| People with similar demographic characteristics should have\n",
      "| similar weights.  There is one important caveat to remember\n",
      "| about this statement.  That is that since the CPS sample is\n",
      "| actually a collection of 51 state samples, each with its own\n",
      "| probability of selection, the statement only applies within\n",
      "| state.\n",
      "\n",
      "\n",
      ">50K, <=50K.\n",
      "\n",
      "age: continuous.\n",
      "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
      "fnlwgt: continuous.\n",
      "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
      "education-num: continuous.\n",
      "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
      "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
      "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
      "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
      "sex: Female, Male.\n",
      "capital-gain: continuous.\n",
      "capital-loss: continuous.\n",
      "hours-per-week: continuous.\n",
      "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open (\"adult/adult.names\", \"r\") as file:\n",
    "    test = file.read()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f0156f4-52ca-4553-814c-ecde99dc08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\" or \"class\"???????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6895e6d7-ed51-4646-9fb6-995c29779e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of adult\n",
      "\n",
      "02 Dec 1996      140 Index\n",
      "10 Aug 1996  3974305 adult.data\n",
      "10 Aug 1996     4267 adult.names\n",
      "10 Aug 1996  2003153 adult.test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open (\"adult/index\", \"r\") as file:\n",
    "    test = file.read()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3eca56be-ad7b-47b3-87c7-844454b1c5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| This data was extracted from the census bureau database found at\n",
      "| http://www.census.gov/ftp/pub/DES/www/welcome.html\n",
      "| Donor: Ronny Kohavi and Barry Becker,\n",
      "|        Data Mining and Visualization\n",
      "|        Silicon Graphics.\n",
      "|        e-mail: ronnyk@sgi.com for questions.\n",
      "| Split into train-test using MLC++ GenCVFiles (2/3, 1/3 random).\n",
      "| 48842 instances, mix of continuous and discrete    (train=32561, test=16281)\n",
      "| 45222 if instances with unknown values are removed (train=30162, test=15060)\n",
      "| Duplicate or conflicting instances : 6\n",
      "| Class probabilities for adult.all file\n",
      "| Probability for the label '>50K'  : 23.93% / 24.78% (without unknowns)\n",
      "| Probability for the label '<=50K' : 76.07% / 75.22% (without unknowns)\n",
      "|\n",
      "| Extraction was done by Barry Becker from the 1994 Census database.  A set of\n",
      "|   reasonably clean records was extracted using the following conditions:\n",
      "|   ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
      "|\n",
      "| Prediction task is to determine whether a person makes over 50K\n",
      "| a year.\n",
      "|\n",
      "| First cited in:\n",
      "| @inproceedings{kohavi-nbtree,\n",
      "|    author={Ron Kohavi},\n",
      "|    title={Scaling Up the Accuracy of Naive-Bayes Classifiers: a\n",
      "|           Decision-Tree Hybrid},\n",
      "|    booktitle={Proceedings of the Second International Conference on\n",
      "|               Knowledge Discovery and Data Mining},\n",
      "|    year = 1996,\n",
      "|    pages={to appear}}\n",
      "|\n",
      "| Error Accuracy reported as follows, after removal of unknowns from\n",
      "|    train/test sets):\n",
      "|    C4.5       : 84.46+-0.30\n",
      "|    Naive-Bayes: 83.88+-0.30\n",
      "|    NBTree     : 85.90+-0.28\n",
      "|\n",
      "|\n",
      "| Following algorithms were later run with the following error rates,\n",
      "|    all after removal of unknowns and using the original train/test split.\n",
      "|    All these numbers are straight runs using MLC++ with default values.\n",
      "|\n",
      "|    Algorithm               Error\n",
      "| -- ----------------        -----\n",
      "| 1  C4.5                    15.54\n",
      "| 2  C4.5-auto               14.46\n",
      "| 3  C4.5 rules              14.94\n",
      "| 4  Voted ID3 (0.6)         15.64\n",
      "| 5  Voted ID3 (0.8)         16.47\n",
      "| 6  T2                      16.84\n",
      "| 7  1R                      19.54\n",
      "| 8  NBTree                  14.10\n",
      "| 9  CN2                     16.00\n",
      "| 10 HOODG                   14.82\n",
      "| 11 FSS Naive Bayes         14.05\n",
      "| 12 IDTM (Decision table)   14.46\n",
      "| 13 Naive-Bayes             16.12\n",
      "| 14 Nearest-neighbor (1)    21.42\n",
      "| 15 Nearest-neighbor (3)    20.35\n",
      "| 16 OC1                     15.04\n",
      "| 17 Pebls                   Crashed.  Unknown why (bounds WERE increased)\n",
      "|\n",
      "| Conversion of original data as follows:\n",
      "| 1. Discretized agrossincome into two ranges with threshold 50,000.\n",
      "| 2. Convert U.S. to US to avoid periods.\n",
      "| 3. Convert Unknown to \"?\"\n",
      "| 4. Run MLC++ GenCVFiles to generate data,test.\n",
      "|\n",
      "| Description of fnlwgt (final weight)\n",
      "|\n",
      "| The weights on the CPS files are controlled to independent estimates of the\n",
      "| civilian noninstitutional population of the US.  These are prepared monthly\n",
      "| for us by Population Division here at the Census Bureau.  We use 3 sets of\n",
      "| controls.\n",
      "|  These are:\n",
      "|          1.  A single cell estimate of the population 16+ for each state.\n",
      "|          2.  Controls for Hispanic Origin by age and sex.\n",
      "|          3.  Controls by Race, age and sex.\n",
      "|\n",
      "| We use all three sets of controls in our weighting program and \"rake\" through\n",
      "| them 6 times so that by the end we come back to all the controls we used.\n",
      "|\n",
      "| The term estimate refers to population totals derived from CPS by creating\n",
      "| \"weighted tallies\" of any specified socio-economic characteristics of the\n",
      "| population.\n",
      "|\n",
      "| People with similar demographic characteristics should have\n",
      "| similar weights.  There is one important caveat to remember\n",
      "| about this statement.  That is that since the CPS sample is\n",
      "| actually a collection of 51 state samples, each with its own\n",
      "| probability of selection, the statement only applies within\n",
      "| state.\n",
      "\n",
      "\n",
      ">50K, <=50K.\n",
      "\n",
      "age: continuous.\n",
      "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
      "fnlwgt: continuous.\n",
      "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
      "education-num: continuous.\n",
      "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
      "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
      "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
      "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
      "sex: Female, Male.\n",
      "capital-gain: continuous.\n",
      "capital-loss: continuous.\n",
      "hours-per-week: continuous.\n",
      "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open (\"adult/adult.names\", \"r\") as file:\n",
    "    test = file.read()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a718eb6-56ac-48a3-8d6d-7627c78fa0ec",
   "metadata": {},
   "source": [
    "####Lab 1 Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7790e7d-9b5e-43bc-9631-1e0e5954e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the split point function that we developed in class and used in assignment 1\n",
    "# when we call it in our program we are iterating through a series of values to determine all splitpoints for the feature\n",
    "\n",
    "def split_point_finder(x):\n",
    "  mid_points_in_column = []\n",
    "  x_sorted = sorted(x)\n",
    "\n",
    "  for i in range(0, len(x)-1):\n",
    "    mid_point = ( (x_sorted[i] + x_sorted[i+1]) / 2)\n",
    "    mid_points_in_column.append(mid_point)\n",
    "  return mid_points_in_column\n",
    "\n",
    "\n",
    "# x here is a single column, we create a list to store the midpoints (len column -1 values)\n",
    "# we sort that column, and for every value from 0 to len -1 we take the average of the current column value and the next\n",
    "# we append these midpoints to the list and return that list, giving us a list of midpoints per column\n",
    "\n",
    "def split_point_finder(x):\n",
    "  mid_points_in_column = []\n",
    "  x_sorted = sorted(x)\n",
    "\n",
    "  for i in range(0, len(x)-1):\n",
    "    mid_point = ( (x_sorted[i] + x_sorted[i+1]) / 2)\n",
    "    mid_points_in_column.append(mid_point)\n",
    "  return mid_points_in_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e280015e-f69b-456e-8fb0-2a320b1dedc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the left and right node function we developed in class and used in assignment 1\n",
    "# we use this to find the x-y pairs that will go to the left and ride nodes given a certain split point, we test all unique split points with this later\n",
    "\n",
    "def branching_splits(x, y, split_point):\n",
    "  mask = x >= split_point\n",
    "  anti_mask = x < split_point\n",
    "  x_right = x[mask]\n",
    "  x_left = x[anti_mask]\n",
    "  y_right = y[mask]\n",
    "  y_left = y[anti_mask]\n",
    "  return x_right, x_left, y_right, y_left\n",
    "\n",
    "\n",
    "\n",
    "# here we pass in the feature column, the label column and the split point we are using\n",
    "# the mask applied filters values greater or equal to the split point\n",
    "# the anti mask is values less than the split point\n",
    "# we then create true/false or right/left lists of the feature column and the label column with the mask filtering\n",
    "# we return the the true/false or right/left list of the feature column and the corresponding label column\n",
    "\n",
    "def branching_splits(x, y, split_point):\n",
    "  mask = x >= split_point\n",
    "  anti_mask = x < split_point\n",
    "  x_right = x[mask]\n",
    "  x_left = x[anti_mask]\n",
    "  y_right = y[mask]\n",
    "  y_left = y[anti_mask]\n",
    "  return x_right, x_left, y_right, y_left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b5ef65-e4be-4233-9b22-c3fce3c70c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we iterate through each feature in dataframe features except for our label column, which is price, but I made it declarable in the function call\n",
    "# we seperate the label data from the rest of the dataframe and then iterate over the remaining columns which are the features\n",
    "# we find the split points for each column, there are many repeats so we make a list of just the unique split point values\n",
    "# I then iterate through those unique split points getting the left and right branching values that are then sent to the MAE function\n",
    "# the mae function calculates the root node MAE and the weighted mae of the leaf nodes for that split point being tested\n",
    "# after getting the MAE values back we store them in a dictionary with this structure key:(feature, split point), value:(root mae, split point mae)\n",
    "# we return the columns we iterated through and the dictionary with the unique split points for each feature and the value pair for the root mae and that split points weighted mae\n",
    "\n",
    "def best_branching_multiple_features(data, label_column_name):\n",
    "\n",
    "  y = data[label_column_name]\n",
    "  features_to_test = data.drop(label_column_name, axis=1)\n",
    "  number_features = len(features_to_test.columns)\n",
    "\n",
    "  feature_error_dictionary = {}\n",
    "\n",
    "\n",
    "  for feature in features_to_test.columns:\n",
    "    x = data[feature]\n",
    "\n",
    "    split_points = split_point_finder(x)\n",
    "    split_points_unique = np.unique(split_points)\n",
    "\n",
    "    for split_point in split_points_unique:\n",
    "      x_right, x_left, y_right, y_left = branching_splits(x, y, split_point)\n",
    "      unique_errors = MAE(y,y_right,y_left)\n",
    "      feature_error_dictionary[feature, split_point] = [unique_errors]\n",
    "\n",
    "  return features_to_test.columns, feature_error_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee2758-b3f8-48f9-9eaa-cd5daa65dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created this function instead of of adding this to the best_branding_multiple_features functions because I felt like the function was too long and harder to understand\n",
    "# this function calls the best_branching_multiple_features function to retrieve the columns we iterated over and the dictionary of split point/ weighted mae values\n",
    "# the goal here is to iterate through the dictionary values for each feature column and find the key/value pair with the lowest weighted mae and record it\n",
    "# This could be implemented into the \" for feature in features_to_test.columns:\" statement in the function that creates the dictionary but I found it more difficult to comprehend\n",
    "# that may be personal prefence though, this adds some computational overhead having to re-iterate through all of the features again, so for very large datasets it would be inefficient\n",
    "# for the upcoming sections we need a way to retrieve the best feature, its split and the weighted mae for any node of a tree so I have chosen to extract those values individually\n",
    "# instead of only bundled in a key,value pair - I am also returning a dictionary of key,value pairs for all of the feature columns incase we need to use a specific one even if its not the best\n",
    "# I iterate through all of the features, within those features we check the dictionary to see if the entry belongs to that feature\n",
    "# if it does then we check to see if that weighted MAE is the lowest so far for that feature, if it is we save it, if not we move on\n",
    "# we do this for each feature, and we also check to see if it is the lowest recorded MAE amongst all features by saving the lowest MAE key,value pair for each feature\n",
    "# after each feature is iterated its lowest MAE key/value is evaluated against the others and the lowest is recorded as the overall best feature, split point and MAE\n",
    "\n",
    "\n",
    "def current_branching_best(data, label_column_name):\n",
    "  tested_features, feature_error_dictionary = best_branching_multiple_features(data, label_column_name)\n",
    "\n",
    "  each_feature_best_split_point = {}\n",
    "  best_overall_feature,best_overall_split_for_feature,best_overall_error_for_feature = None, None, float('inf')\n",
    "\n",
    "  for feature in tested_features:\n",
    "    best_error_for_current_feature, best_split_for_current_feature = float('inf'), None\n",
    "\n",
    "    for (this_feature, this_split_point), error_value_pair in feature_error_dictionary.items():\n",
    "\n",
    "      if this_feature == feature:\n",
    "        error_pair = error_value_pair[0]\n",
    "        split_mae = error_pair[1]\n",
    "\n",
    "        if split_mae < best_error_for_current_feature:\n",
    "          best_error_for_current_feature = split_mae\n",
    "          best_split_for_current_feature = this_split_point\n",
    "    each_feature_best_split_point[feature, best_split_for_current_feature] =(error_pair[0], best_error_for_current_feature)\n",
    "\n",
    "    if best_error_for_current_feature < best_overall_error_for_feature:\n",
    "      best_overall_error_for_feature = best_error_for_current_feature\n",
    "      best_overall_feature = feature\n",
    "      best_overall_split_for_feature = best_split_for_current_feature\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  return best_overall_feature, best_overall_split_for_feature, best_overall_error_for_feature, each_feature_best_split_point\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "64ed8cf2-3ddb-46a7-a595-9a482ff2488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is pulled from assignment 1 and has a few slight modifications\n",
    "# this functions purpose is to find the best split point and feature at each node of the decision tree\n",
    "# it then returns the feature, split point, root node mse, branching leaf node weighted mse and the dictionary of all errors for the features tested\n",
    "\n",
    "# what we have modified in this code is the ability to randomly select features at each node of the tree, a subset of the total training dataset features\n",
    "# we do this by taking num_random_features_to_choose making it a parameter that can be adjusted in our decision tree creation function\n",
    "# we specify the number of features we want to randomly choose, then before we begin looping for the feautures looking for the best feature / split point\n",
    "# we randomly select from our total features in the dataset columns the parameter number of features to test for the splitting at this node\n",
    "# so if we have a parameter of 5 and 17 feature columns in our dataframe, we randomly choose 5 of those 17 with duplicates not being allowed\n",
    "# from there the function works the same way as assignment 1 where we determine the best split point and feature from those we test to determine the best splitting for this node\n",
    "\n",
    "# we pass in the bootstrap data to this function not the total training dataset\n",
    "def best_branching_random_features(data, label_column_name, num_random_features_to_choose):\n",
    "\n",
    "  y = data[label_column_name]\n",
    "  possible_features_to_test = data.drop(label_column_name, axis=1) # drop the label column from the dataframe so only features are left\n",
    "\n",
    "  randomized_features_this_node = rng.choice(possible_features_to_test.columns, num_random_features_to_choose, replace = False)\n",
    "  # we use rng.choice to randomly choose (parameter number of features) from (all feature columns that are present in the dataframe) and don't allow duplicates\n",
    "\n",
    "  this_node_data = possible_features_to_test[randomized_features_this_node].copy() # then we create a new dataframe only copying the feature columns selected by our random feature selector above\n",
    "  # we get a smaller dataframe with only the number of features declared in the function parameter\n",
    "\n",
    "  feature_error_dictionary = {}\n",
    "\n",
    "  # In assignment 1 we wouldn't have ran into these errors, but I ran into an error for each of these variables not being initialized\n",
    "  # min error should be set to inf, anythign smaller will replace it\n",
    "  minimum_error = float('inf')\n",
    "\n",
    "  # these 3 can create errors further down our decision tree building if no split points are found to reduce the minimum error, if they arent initialized now and we go to return them\n",
    "  # then we get the errors I pasted in below - if your testing a split with only has 100 samples and for a feature they are all the same value, then no split point exists and these\n",
    "  # values would be left un-initialized given our structure below\n",
    "  node_mse = float('inf')\n",
    "  best_feature = 'Kelton'\n",
    "  best_split_point_current_feature = 992018683\n",
    "  #UnboundLocalError: cannot access local variable 'best_feature' where it is not associated with a value\n",
    "  #UnboundLocalError: cannot access local variable 'node_mse' where it is not associated with a value\n",
    "  #UnboundLocalError: cannot access local variable 'best_split_point_current_feature' where it is not associated with a value\n",
    "\n",
    "  for feature in this_node_data.columns:\n",
    "    x = data[feature]\n",
    "\n",
    "    split_points = split_point_finder(x)\n",
    "    split_points_unique = np.unique(split_points)\n",
    "\n",
    "    for split_point in split_points_unique:\n",
    "      x_right, x_left, y_right, y_left = branching_splits(x, y, split_point)\n",
    "      unique_errors = weighted_branch_MSE(y,y_right,y_left)\n",
    "      feature_error_dictionary[feature, split_point] = [unique_errors]\n",
    "\n",
    "        # recording the best feature and split point based on lowest weighted branch mse from the mse function\n",
    "      if unique_errors[1] < minimum_error:\n",
    "        minimum_error = unique_errors[1]\n",
    "        node_mse = unique_errors[0]\n",
    "        best_feature = feature\n",
    "        best_split_point_current_feature = split_point\n",
    "\n",
    "  return feature_error_dictionary, node_mse, minimum_error, best_feature, best_split_point_current_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6085a420-7336-419b-9da0-0d97442cdecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing that the best_branching_random_features function delivers the best split point, feature, and mse of leaves along with root node mse\n",
    "def main(data, label_column_name, num_randomized_features):\n",
    "  total_samples = data.shape[0]\n",
    "\n",
    "  dictionary_of_errors_for_node, root_mse, branch_mse, feature, split_point = best_branching_random_features(data, label_column_name, num_randomized_features)\n",
    "\n",
    "  print(root_mse)\n",
    "  print(branch_mse)\n",
    "  print(feature)\n",
    "  print(split_point)\n",
    "\n",
    "  return dictionary_of_errors_for_node, root_mse, branch_mse, feature, split_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8dc8d55e-07d0-4038-9097-d7e365f8c5c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_sample_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mcnair_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_sample_train\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      2\u001b[0m label_column_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m number_of_random_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msqrt((mcnair_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# rounds down to 4\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_sample_train' is not defined"
     ]
    }
   ],
   "source": [
    "mcnair_data = data_sample_train.copy()\n",
    "label_column_name = 'price'\n",
    "number_of_random_features = int(np.sqrt((mcnair_data.shape[1])-1)) # rounds down to 4\n",
    "\n",
    "\n",
    "dictionary_of_errors_for_node, root_mse, branch_mse, feature, split_point = main(bootstrap, label_column_name, number_of_random_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c1584-0ba3-4b8f-94d3-42a67c676a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = []\n",
    "for feature, split_point in dictionary_of_errors_for_node:\n",
    "  features.append(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb3e10-047d-4941-9b7f-a1b034b1e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa83268-39a6-4208-b310-2227c8f44faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is my decision tree builder function, which is similar to that of which was built in class but I went with a dictionary instead of a tuple return type\n",
    "# I have set parameters for max depth of the tree, minimum number of samples in a node to try to split it, and a minimum number of samples in the resulting leaves to continue with the splitting\n",
    "\n",
    "\n",
    "def dt_builder(bootstrap_current_node, label_column_name, num_randomized_features, minimum_samples_per_leaf, min_samples_per_split, max_depth, depth = 0):\n",
    "\n",
    "  before_split_sample_size = bootstrap_current_node.shape[0]# get the number of samples in the current parent node\n",
    "\n",
    "\n",
    "  # this is like the max depth checker in the in-class example, but we must also check to make sure that there are enough samples in the parent node to even determine if splitting is worthwhile\n",
    "  if depth >= max_depth or before_split_sample_size < min_samples_per_split: # if depth is >= max depth or there arent enough samples in the parent node then we return a prediction\n",
    "    return {\"prediction_this_node\": np.mean(bootstrap_current_node[label_column_name])}\n",
    "\n",
    "  # we have not reached max depth or the minimum number of samples in the parent node, so we call our function to find the best splitting at this node\n",
    "  # we pass thorugh the current node sample, the label, and the number of features to randomly choose\n",
    "  dictionary_of_errors_for_node, root_mse, branch_mse, feature, split_point = best_branching_random_features(bootstrap_current_node, label_column_name, num_randomized_features)\n",
    "\n",
    "\n",
    "  # this is where I began getting errors for the uninitialized best feature, split and root mse in our branching function\n",
    "  # I have initialized the best feature to my name, if this is returned that means there were no valid split points found in the features randomly selected\n",
    "  # this seems to be due to a small number of samples in the node and the sample feature values being the same, like all having 1.0 floors as an example, no splits found so kelton is returned\n",
    "  # in the case that this non-feature basecase is returned we can no longer split and return this node as a prediction node\n",
    "  if feature == 'Kelton':\n",
    "    # print(feature) # testing\n",
    "    return {\"prediction_this_node\": np.mean(bootstrap_current_node[label_column_name])}\n",
    "\n",
    "  # just like branching splits we use vectorized operations on the current node to get the data for the resulting left and right leaf nodes from the split\n",
    "  # I suppose you could store these in the error dictionary from the best_branching_random_features from above\n",
    "  left_node_data = bootstrap_current_node[bootstrap_current_node[feature] < split_point]\n",
    "\n",
    "  right_node_data = bootstrap_current_node[bootstrap_current_node[feature] >= split_point]\n",
    "\n",
    "  # this gets the size of the resulting split leaf nodes, left and right, from the lead node data sets, we get the sizes to check the leaf node sample sizes against the minimum\n",
    "  left_sample_size = left_node_data.shape[0]\n",
    "  right_sample_size = right_node_data.shape[0]\n",
    "\n",
    "  # here we are checking if both the left and right resulting leaf node samples from splitting are greater than or equal to the minimum value parameter we have set\n",
    "  # if either is less than the parameter threshold we do not do the node split and we return the node as a prediction node instead\n",
    "  if left_sample_size < minimum_samples_per_leaf or right_sample_size < minimum_samples_per_leaf:\n",
    "    return {\"prediction_this_node\": np.mean(bootstrap_current_node[label_column_name])}\n",
    "\n",
    " # these are our recrusive calls to this function, for the left nodes and right nodes, each time we increase the depth by 1 so we know if we need to stop the branching due to depth\n",
    " # these calls are what create the tree leaf structure below the root node which is created the first time we call this function\n",
    "  left_leaf_node = dt_builder(left_node_data, label_column_name, num_randomized_features, minimum_samples_per_leaf, min_samples_per_split, max_depth, depth + 1)\n",
    "  right_leaf_node = dt_builder(right_node_data, label_column_name, num_randomized_features, minimum_samples_per_leaf, min_samples_per_split, max_depth, depth + 1)\n",
    "\n",
    "  # just like our tuple return from the in class version of this code, we return the feature, the split point, the left leaf node and right leaf node, in dictionary form instead of tuples\n",
    "  return { \"feature\": feature, \"split_point\": split_point, \"left_leaf_node\": left_leaf_node, \"right_leaf_node\": right_leaf_node}\n",
    "  # I had dynamic depth tracking in the key of the leaf nodes, but that was making tree navigation more difficult so I opted to remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e8e57-1879-4a60-b3ae-420b076e285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_traversal(individual_tree, test_data):\n",
    "# in the in class version with tuples and different data format, we can check if isinstance tree,float - which wouldn't work for multiple reasons in this assignment\n",
    "# I have opted for the decision tree to be a dictionary format instead of a tuple, both are hard to read though\n",
    "# instead of checking for a float, because I have set a key for when a node becomes a prediciton, we check for the key \"prediction_this_node\" each time we call this function, and when it finds this key it returns\n",
    "# the prediction value that is associated with that node\n",
    "  if \"prediction_this_node\" in individual_tree:\n",
    "    return individual_tree[\"prediction_this_node\"]\n",
    "\n",
    "  # we need to pull the feature and split point values from each dictionary entry to traverse further down, once we have the feature and the split we can test the value of the feature of the sample datapoint against the split point\n",
    "  # so we use the keys to get the values\n",
    "  current_feature = individual_tree[\"feature\"]\n",
    "  current_split_point = individual_tree[\"split_point\"]\n",
    "\n",
    "\n",
    "  # if the value for this samples feature value is less than the split point we traverse to the left child node\n",
    "  # if the value for this samples feature value is greater than or equal to the split point then we traverse to the right child node\n",
    "  # this traversal will come to an end when we encounter the key indicating a prediciton node\n",
    "  if test_data[current_feature] < current_split_point:\n",
    "    return predict_traversal(individual_tree[\"left_leaf_node\"], test_data) # go to the next left node\n",
    "  else:\n",
    "    return predict_traversal(individual_tree[\"right_leaf_node\"], test_data) # go to the next right node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45358565-a112-4811-9de6-603ad5fac317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a single test decision tree, min samples, min samples to even try to split is at least 2x the minimum samples per leaf\n",
    "# I was trying to experiment with setting the min samples to consider splitting higher than 2x the min samples per leaf\n",
    "# max depth of 10, https://www.geeksforgeeks.org/how-to-choose-ideal-decision-tree-depth-without-overfitting/\n",
    "# in the link they are using a classifier model, so this may be irrelevant to a regression model\n",
    "# but they test depths from 1-15 and their accuraccy seems to almost peak around a max depth of 7\n",
    "# I have been testing between 3-12 and I seem to be getting the best results around 8-12 given the parameter of 4 randomly chosen features I have been using,\n",
    "mcnair_data = data_sample_train.copy()\n",
    "label_column_name = 'price'\n",
    "num_randomized_features = int(np.sqrt((mcnair_data.shape[1]-1)))\n",
    "minimum_samples_per_leaf = 12\n",
    "min_samples_per_split = (minimum_samples_per_leaf * 2) + 1\n",
    "max_depth = 10\n",
    "bootstrap_sample_size = mcnair_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd56214-500a-4b1d-8733-103a9cc4a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap_current_node, all_oob = boot_strap_and_oob(data, label_column_name, bootstrap_sample_size)\n",
    "    individual_tree_dict = dt_builder(bootstrap_current_node, label_column_name, num_randomized_features, minimum_samples_per_leaf, min_samples_per_split, max_depth, depth = 0)\n",
    "    individual_tree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ae5f8-b9be-49b1-bd31-cc199b2be52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53e060b5-73a4-4bb4-9b22-8a8aabd62031",
   "metadata": {},
   "source": [
    "####Lab 2 Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc5a01-ba19-4955-8678-b260c83fb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this function I am taking in the training dataset, the label and the total number of train samples\n",
    "# for each training sample in the dataset we randomly grab a row from the training dataset to create our bootstrap dataset\n",
    "# so in our case we have a training dataset of 8500, so we create a bootstrap that has 8500 samples from our original train dataset\n",
    "# we get indices to pull from the training set randomly by generating a random # from 0 to 8499 and adding that row to our array\n",
    "# once we have created our array of samples from the rows of the training dataset, we create the bootstrap dataset from our array of rows\n",
    "# this method will allow duplicates, and with this many samples we should end up with roughly 65% of the train dataset in our bootstrap\n",
    "# then we seperate the label column from the X_bootstrap resulting in just the training data with no label\n",
    "# then y_bootstrap is just the labels column, but all of the indices match up\n",
    "\n",
    "def bootstrap_creator(this_tree_data, label_column_name, total_samples):\n",
    "  bootstrap_for_this_tree = [] # holder array\n",
    "\n",
    "  for i in range(total_samples): # match size of bootstrap to size of training data set\n",
    "    random_index_to_add = np.random.randint(0 , total_samples) # generate a row index to grab from the training datatset\n",
    "    bootstrap_for_this_tree.append(this_tree_data.iloc[random_index_to_add]) # add that dataset row to our array\n",
    "\n",
    "\n",
    "    #create the bootstrap dataframe\n",
    "  bootstrap = pd.DataFrame(bootstrap_for_this_tree) # I suppose I could have np.unique before creating the dataframe here - nevermind that didn't work how I intended\n",
    "\n",
    "    # generate X and Y bootstraps from bootstrap\n",
    "  X_bootstrap = bootstrap.drop(label_column_name, axis=1)\n",
    "  y_bootstrap = bootstrap[label_column_name]\n",
    "\n",
    "  return X_bootstrap, y_bootstrap, bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfefa49-7fd3-4581-81b2-bc583ba467ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to calculate the rows from the training dataset that did not make it into this bootstrap dataset\n",
    "# we pass in the label, the training dataset and the randomly selected bootstrap dataset\n",
    "# with a dataframe this is a bit simpler than with the all integer numpy array from the class example\n",
    "# here we can simply drop all of the indices (rows) that exist in the bootstrap data set from the training data set and we are left with the out of box sample set\n",
    "# I didn't need to copy the dataframe, I find myself doing this somewhat often when I am working with dataframes to maintain the last version of them\n",
    "# I want to say I picked up this habit during my AI course but I don't remember why exactly, I think it had to do with model evaluations\n",
    "# then to find the data frames for X_oob and y_oob we simply drop the label from our total oob dataframe for X and pull out only the label column for our y\n",
    "\n",
    "def oob_determination(tree_data, bootstrap, label_column_name):\n",
    "\n",
    "    # drop bootstrap rows from the total tree training data set to be left with a dataframe of only the none-selected training samples\n",
    "  oob_for_this_tree = tree_data.drop(index=bootstrap.index) # drop all the indices from the tree dataset/ training dataset that exist within the bootstrap for this specific tree\n",
    "\n",
    "    # copy oob_for_this_tree incase we need to pass it as a return later\n",
    "  all_oob_this_tree = oob_for_this_tree.copy()\n",
    "\n",
    "    # make the X-oob and y_oob respective dataframes\n",
    "  X_oob = oob_for_this_tree.drop(label_column_name, axis=1)\n",
    "  y_oob = oob_for_this_tree[label_column_name]\n",
    "\n",
    "  return X_oob, y_oob, all_oob_this_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7f3947-8e0e-48d0-917e-88d0761fadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function calls the bootstrap creation function and then passes the bootstrap dataset into oob to return the oob values\n",
    "# meaning bootstrap + oob below make up the entirety of the 8500 data samples within sample_data_train without any overlap\n",
    "# and this function just returns the output of both lumped together\n",
    "def boot_strap_and_oob(tree_data, label_column_name, total_samples):\n",
    "  X_bootstrap, y_bootstrap, bootstrap = bootstrap_creator(tree_data, label_column_name, total_samples)\n",
    "  X_oob, y_oob, all_oob = oob_determination(tree_data, bootstrap, label_column_name)\n",
    "\n",
    "  return X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap, all_oob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602edc64-1836-462a-805f-cad6b4e280ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration of these functions working correctly, passing in the the training sample number of samples and retreiving all of the bootstrap & oob data frames\n",
    "def main_test_bs(data, label_column_name):\n",
    "  total_samples = data.shape[0]\n",
    "  X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap, all_oob = boot_strap_and_oob(data, label_column_name, total_samples)\n",
    "  return X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap, all_oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688741d-b214-40c6-b39e-9431fd17c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnair_data = data.copy()\n",
    "label_column_name = 'income'\n",
    "\n",
    "X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap, all_oob = main_test_bs(mcnair_data, label_column_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cc3a3-0826-4987-bdd4-0108098055fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap.drop_duplicates().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8453ef0-73eb-44e6-b0d4-587abd5142a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_oob.drop_duplicates().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28fa17-c7ac-494d-a61d-326a378ebdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dee369c-a69b-47f2-a733-92be6540e0af",
   "metadata": {},
   "source": [
    "Working on getting multiprocessing setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53f32a-5852-4308-b49a-d4a191c3bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool # multiprocessing but requires function to be in a .py file when working with jupyter?\n",
    "from multiprocessing import get_context #older fork method not newer spawn, issues with this also, need to put functions in .py file maybe\n",
    "\n",
    "# https://docs.python.org/3.10/library/multiprocessing.html\n",
    "# https://stackoverflow.com/questions/72830743/multiprocessing-changed-in-python-3-9-from-3-7-on-macosx-how-to-fix\n",
    "# https://machinelearningmastery.com/multiprocessing-in-python/\n",
    "# https://medium.com/@dialoglk/boosting-performance-and-efficiency-exploring-the-advantages-of-multiprocessing-in-python-fd48202e1107\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee38d6-7315-4f89-8d31-baaf19385df4",
   "metadata": {},
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c4bb93-eba1-4de4-9298-42a97f86040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to figure out Criterion for determining the best feature split (Gini impurity or Entropy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
