{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e092cd7-1711-4e81-8f76-d65719cfe3c4",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbff71d-1ed4-41e8-842e-430cd81f1c20",
   "metadata": {},
   "source": [
    "## Kelton McNair - 992018683\n",
    "### CS 601 - Machine Learning\n",
    "### Spring Semester Project 2025\n",
    "### Dr. Afshar\n",
    "### Random Forest Classifier\n",
    "### Dataset: Adult "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cac141-462e-4e23-a137-4a0bf8f679c7",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a9f424-5098-4214-beb8-afe37b923c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ucimlrepo\n",
    "\n",
    "# from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# # fetch dataset \n",
    "# adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "# X = adult.data.features \n",
    "# y = adult.data.targets \n",
    "  \n",
    "# # metadata \n",
    "# print(adult.metadata) \n",
    "  \n",
    "# # variable information \n",
    "# print(adult.variables) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18976bf9-2f7e-4092-9cb1-1cc1de604d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(1995)\n",
    "import pandas as pd\n",
    "\n",
    "# these were not implemented / used after all as I did not have the time to fully implement multiprocessing to speed up the tree building\n",
    "from mcnair_rf_classifier import imported_random_forest_classifier\n",
    "from multiprocessing import Pool # multiprocessing but requires function to be in a .py file when working with jupyter?\n",
    "from multiprocessing import get_context #older fork method not newer spawn, issues with this also, need to put functions in .py file maybe\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b1a78a4-4025-4938-8d47-95ef80c82113",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"adult/adult.data\") #na_values didnt work\n",
    "# read in the data as a dataframe, I tried na_values and na_filter but the missing values are not NA, null, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefd73ed-a649-44ad-a4d4-e6a72d9505a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the columns names that I found in adult.names\n",
    "extracted_col_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0721cf4-fcf1-4c24-a26d-626da02e65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = extracted_col_names\n",
    "# adding the column names to the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72848efb-24d7-4c0d-91f3-27caa31ea87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>260254</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12349</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>117779</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31068</th>\n",
       "      <td>26</td>\n",
       "      <td>Private</td>\n",
       "      <td>226196</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt education  education-num  marital-status  \\\n",
       "6214    23   Private  260254   HS-grad              9   Never-married   \n",
       "12349   32   Private  117779   HS-grad              9   Never-married   \n",
       "31068   26   Private  226196   HS-grad              9   Never-married   \n",
       "\n",
       "              occupation relationship    race      sex  capital-gain  \\\n",
       "6214               Sales    Own-child   White     Male             0   \n",
       "12349   Transport-moving    Own-child   White   Female             0   \n",
       "31068   Transport-moving    Own-child   White     Male             0   \n",
       "\n",
       "       capital-loss  hours-per-week  native-country  income  \n",
       "6214              0              40   United-States   <=50K  \n",
       "12349             0              35   United-States   <=50K  \n",
       "31068             0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0854f978-62cb-43c3-95af-675943256355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32560 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0      False      False   False      False          False           False   \n",
       "1      False      False   False      False          False           False   \n",
       "2      False      False   False      False          False           False   \n",
       "3      False      False   False      False          False           False   \n",
       "4      False      False   False      False          False           False   \n",
       "...      ...        ...     ...        ...            ...             ...   \n",
       "32555  False      False   False      False          False           False   \n",
       "32556  False      False   False      False          False           False   \n",
       "32557  False      False   False      False          False           False   \n",
       "32558  False      False   False      False          False           False   \n",
       "32559  False      False   False      False          False           False   \n",
       "\n",
       "       occupation  relationship   race    sex  capital-gain  capital-loss  \\\n",
       "0           False         False  False  False         False         False   \n",
       "1           False         False  False  False         False         False   \n",
       "2           False         False  False  False         False         False   \n",
       "3           False         False  False  False         False         False   \n",
       "4           False         False  False  False         False         False   \n",
       "...           ...           ...    ...    ...           ...           ...   \n",
       "32555       False         False  False  False         False         False   \n",
       "32556       False         False  False  False         False         False   \n",
       "32557       False         False  False  False         False         False   \n",
       "32558       False         False  False  False         False         False   \n",
       "32559       False         False  False  False         False         False   \n",
       "\n",
       "       hours-per-week  native-country  income  \n",
       "0               False           False   False  \n",
       "1               False           False   False  \n",
       "2               False           False   False  \n",
       "3               False           False   False  \n",
       "4               False           False   False  \n",
       "...               ...             ...     ...  \n",
       "32555           False           False   False  \n",
       "32556           False           False   False  \n",
       "32557           False           False   False  \n",
       "32558           False           False   False  \n",
       "32559           False           False   False  \n",
       "\n",
       "[32560 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e6260ea-6f97-4b0f-a472-eeb089d6ff76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education-num     0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours-per-week    0\n",
       "native-country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "006675ea-0a79-429f-8a38-1c1227370a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               False\n",
       "workclass         False\n",
       "fnlwgt            False\n",
       "education         False\n",
       "education-num     False\n",
       "marital-status    False\n",
       "occupation        False\n",
       "relationship      False\n",
       "race              False\n",
       "sex               False\n",
       "capital-gain      False\n",
       "capital-loss      False\n",
       "hours-per-week    False\n",
       "native-country    False\n",
       "income            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are not seeing any NA values or missing values, but if we check value counts below, we see that there are values with a ? as the value\n",
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c0546f0-bc56-49f1-9963-22e2345068da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "36    898\n",
      "31    888\n",
      "34    886\n",
      "23    877\n",
      "35    876\n",
      "     ... \n",
      "83      6\n",
      "88      3\n",
      "85      3\n",
      "86      1\n",
      "87      1\n",
      "Name: count, Length: 73, dtype: int64\n",
      "workclass\n",
      "Private             22696\n",
      "Self-emp-not-inc     2541\n",
      "Local-gov            2093\n",
      "?                    1836\n",
      "State-gov            1297\n",
      "Self-emp-inc         1116\n",
      "Federal-gov           960\n",
      "Without-pay            14\n",
      "Never-worked            7\n",
      "Name: count, dtype: int64\n",
      "fnlwgt\n",
      "164190    13\n",
      "203488    13\n",
      "123011    13\n",
      "148995    12\n",
      "126675    12\n",
      "          ..\n",
      "325573     1\n",
      "140176     1\n",
      "318264     1\n",
      "329205     1\n",
      "257302     1\n",
      "Name: count, Length: 21647, dtype: int64\n",
      "education\n",
      "HS-grad         10501\n",
      "Some-college     7291\n",
      "Bachelors        5354\n",
      "Masters          1723\n",
      "Assoc-voc        1382\n",
      "11th             1175\n",
      "Assoc-acdm       1067\n",
      "10th              933\n",
      "7th-8th           646\n",
      "Prof-school       576\n",
      "9th               514\n",
      "12th              433\n",
      "Doctorate         413\n",
      "5th-6th           333\n",
      "1st-4th           168\n",
      "Preschool          51\n",
      "Name: count, dtype: int64\n",
      "education-num\n",
      "9     10501\n",
      "10     7291\n",
      "13     5354\n",
      "14     1723\n",
      "11     1382\n",
      "7      1175\n",
      "12     1067\n",
      "6       933\n",
      "4       646\n",
      "15      576\n",
      "5       514\n",
      "8       433\n",
      "16      413\n",
      "3       333\n",
      "2       168\n",
      "1        51\n",
      "Name: count, dtype: int64\n",
      "marital-status\n",
      "Married-civ-spouse       14976\n",
      "Never-married            10682\n",
      "Divorced                  4443\n",
      "Separated                 1025\n",
      "Widowed                    993\n",
      "Married-spouse-absent      418\n",
      "Married-AF-spouse           23\n",
      "Name: count, dtype: int64\n",
      "occupation\n",
      "Prof-specialty       4140\n",
      "Craft-repair         4099\n",
      "Exec-managerial      4066\n",
      "Adm-clerical         3769\n",
      "Sales                3650\n",
      "Other-service        3295\n",
      "Machine-op-inspct    2002\n",
      "?                    1843\n",
      "Transport-moving     1597\n",
      "Handlers-cleaners    1370\n",
      "Farming-fishing       994\n",
      "Tech-support          928\n",
      "Protective-serv       649\n",
      "Priv-house-serv       149\n",
      "Armed-Forces            9\n",
      "Name: count, dtype: int64\n",
      "relationship\n",
      "Husband           13193\n",
      "Not-in-family      8304\n",
      "Own-child          5068\n",
      "Unmarried          3446\n",
      "Wife               1568\n",
      "Other-relative      981\n",
      "Name: count, dtype: int64\n",
      "race\n",
      "White                 27815\n",
      "Black                  3124\n",
      "Asian-Pac-Islander     1039\n",
      "Amer-Indian-Eskimo      311\n",
      "Other                   271\n",
      "Name: count, dtype: int64\n",
      "sex\n",
      "Male      21789\n",
      "Female    10771\n",
      "Name: count, dtype: int64\n",
      "capital-gain\n",
      "0        29849\n",
      "15024      347\n",
      "7688       284\n",
      "7298       246\n",
      "99999      159\n",
      "         ...  \n",
      "1111         1\n",
      "2538         1\n",
      "22040        1\n",
      "4931         1\n",
      "5060         1\n",
      "Name: count, Length: 119, dtype: int64\n",
      "capital-loss\n",
      "0       31041\n",
      "1902      202\n",
      "1977      168\n",
      "1887      159\n",
      "1848       51\n",
      "        ...  \n",
      "2080        1\n",
      "1539        1\n",
      "1844        1\n",
      "2489        1\n",
      "1411        1\n",
      "Name: count, Length: 92, dtype: int64\n",
      "hours-per-week\n",
      "40    15216\n",
      "50     2819\n",
      "45     1824\n",
      "60     1475\n",
      "35     1297\n",
      "      ...  \n",
      "82        1\n",
      "94        1\n",
      "92        1\n",
      "74        1\n",
      "87        1\n",
      "Name: count, Length: 94, dtype: int64\n",
      "native-country\n",
      "United-States                 29169\n",
      "Mexico                          643\n",
      "?                               583\n",
      "Philippines                     198\n",
      "Germany                         137\n",
      "Canada                          121\n",
      "Puerto-Rico                     114\n",
      "El-Salvador                     106\n",
      "India                           100\n",
      "Cuba                             95\n",
      "England                          90\n",
      "Jamaica                          81\n",
      "South                            80\n",
      "China                            75\n",
      "Italy                            73\n",
      "Dominican-Republic               70\n",
      "Vietnam                          67\n",
      "Guatemala                        64\n",
      "Japan                            62\n",
      "Poland                           60\n",
      "Columbia                         59\n",
      "Taiwan                           51\n",
      "Haiti                            44\n",
      "Iran                             43\n",
      "Portugal                         37\n",
      "Nicaragua                        34\n",
      "Peru                             31\n",
      "France                           29\n",
      "Greece                           29\n",
      "Ecuador                          28\n",
      "Ireland                          24\n",
      "Hong                             20\n",
      "Cambodia                         19\n",
      "Trinadad&Tobago                  19\n",
      "Laos                             18\n",
      "Thailand                         18\n",
      "Yugoslavia                       16\n",
      "Outlying-US(Guam-USVI-etc)       14\n",
      "Honduras                         13\n",
      "Hungary                          13\n",
      "Scotland                         12\n",
      "Holand-Netherlands                1\n",
      "Name: count, dtype: int64\n",
      "income\n",
      "<=50K    24719\n",
      ">50K      7841\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# for every column in the dataframe we print the value counts for that column\n",
    "# we can see that there aren't any values that are NA/NULL but there are what I am guessing are missing values, represented by a '?'.\n",
    "for col in data.columns:\n",
    "    print(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31c02ae4-740f-4a7b-82a9-989820ffcce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age - int64\n",
      "workclass - object\n",
      "fnlwgt - int64\n",
      "education - object\n",
      "education-num - int64\n",
      "marital-status - object\n",
      "occupation - object\n",
      "relationship - object\n",
      "race - object\n",
      "sex - object\n",
      "capital-gain - int64\n",
      "capital-loss - int64\n",
      "hours-per-week - int64\n",
      "native-country - object\n",
      "income - object\n"
     ]
    }
   ],
   "source": [
    "cols_categorical = [] # we use this in about 15 cells\n",
    "\n",
    "# for every feature column we get the datatype of each column as we iterate through\n",
    "# then I check if the column datatype is int64 or float 64, ie numerical, and if it is not numerical\n",
    "# then we append those columns to our categorical columns list and we strip empty space from the category values\n",
    "# (the missing values had leading or trailing whitespace) \n",
    "for col in data.columns:\n",
    "    current_data_type = data[col].dtype \n",
    "    print(col,'-',current_data_type)\n",
    "    if current_data_type != 'int64' and current_data_type != 'float64':\n",
    "        cols_categorical.append(col)\n",
    "        data[col] = data[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8533c50-7a47-4401-ba7c-3e3e2690d785",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  0\n",
      "workclass         1836\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education-num        0\n",
      "marital-status       0\n",
      "occupation        1843\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     583\n",
      "income               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# I had to strip the empty space from the categorical column values because this lambda function searching for ? wasn't working\n",
    "# until I striped the whitespace\n",
    "\n",
    "# this lambda function we use to get the sum of all '?' by category, we can technically see these values above in value counts\n",
    "# we apply this col == ? on each col of the dataframe, returning a series with the original column names as the indices\n",
    "# and a sum of the boolean 1 counts from the col == ? expression\n",
    "question_marks = data.apply(lambda col: (col == '?').sum())\n",
    "\n",
    "print (question_marks)\n",
    "\n",
    "# we see that there are anywhere between 1836 and 1836+1843+583 total samples with a ?\n",
    "# given that we are encoding with oneHot / dummy encoding, can you leave a ?, will be encoded into its own category bucket?\n",
    "# or in this situation is it better to try and apply a \"nearby\" or similar value for these samples categories through something like knn/clustering/other method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00da1949-bd71-4831-9c31-557a7f1279e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'native-country',\n",
       " 'income']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b8371d5-4272-4ab8-9e34-b9c3a5342967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rechecking value counts, whitespace stripping worked\n",
    "# for col in data.columns:\n",
    "#     print(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dfb479a-d9b6-49d9-a4fd-2854a6cd6583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples with missing values as a '?': 2399\n"
     ]
    }
   ],
   "source": [
    "# if rows with missing values are > x% we need to do something with them\n",
    "# if rows with missing values are <x% we can drop them\n",
    "# what is x?\n",
    "# what do we do with those rows if %>x? \n",
    "\n",
    "\n",
    "\n",
    "# here we create an array to hold indices for rows with ? values\n",
    "rows_with_question = []\n",
    "\n",
    "for index, sample in data.iterrows(): # iterate through the indices - samples/rows of our dataframe via iterrows (ittertupples, .items, etc.. are options)\n",
    "    if \"?\" in sample.values: # as we iterate over each sample, we check if any of the values of that sample are a ?\n",
    "        rows_with_question.append(index) # if they are, then we append the index to our list\n",
    "print(\"# of samples with missing values as a '?':\",len(rows_with_question)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06a0e20d-4052-4b80-b4c3-ecfde66b874c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07367936117936118"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows_with_question) / data.shape[0] # 7.368% of our samples have a missing value denoted with ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5468524-b680-4398-9b7f-4648a0215741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With only 7.36% of the samples having a missing value, we will just drop those\n",
    "# The dataset currently isn't balanced in the target / label feature column \n",
    "# =<50k income has roughly 3x the number of samples than >50k income\n",
    "# But we can select a balanced mix of either during bootstraping to combat this\n",
    "# resulting in bootstraps over 10k values still, and we will get a lot of variance in the =<50k bootstraps between trees because there will be more to choose from\n",
    "# if all 7.5% of the samples were in the lower sample count category of your label, it may be worth considering value replacement for them\n",
    "# this would be important if you didn't have enough samples in that lesser value count label category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c85453e-4937-4e82-bc62-02bd265fba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_Data = data.drop(index=rows_with_question) # here we drop the samples from our dataframe that we gathered in which contain a ? value\n",
    "# and we initialize this as cleaned_Data\n",
    "\n",
    "# running value counts shows the ? value categories are now gone\n",
    "# for col in cleaned_Data.columns:\n",
    "#     print(cleaned_Data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19a8cd3e-34ee-477f-9f4d-b94c796181bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "income            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "question_marks_cleaned = cleaned_Data.apply(lambda col: (col == '?').sum())\n",
    "# here we apply our lambda function again to our new dataframe of cleaned_Data\n",
    "# we see below that there are no more ? values in any of our features\n",
    "print (question_marks_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70800b7b-9e09-47ae-885b-321cfd9f3e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>160187</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>209642</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>45781</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14084</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>159449</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>280464</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>141297</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>India</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>122272</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>205019</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>245487</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age         workclass  fnlwgt     education  education-num  \\\n",
       "0    50  Self-emp-not-inc   83311     Bachelors             13   \n",
       "1    38           Private  215646       HS-grad              9   \n",
       "2    53           Private  234721          11th              7   \n",
       "3    28           Private  338409     Bachelors             13   \n",
       "4    37           Private  284582       Masters             14   \n",
       "5    49           Private  160187           9th              5   \n",
       "6    52  Self-emp-not-inc  209642       HS-grad              9   \n",
       "7    31           Private   45781       Masters             14   \n",
       "8    42           Private  159449     Bachelors             13   \n",
       "9    37           Private  280464  Some-college             10   \n",
       "10   30         State-gov  141297     Bachelors             13   \n",
       "11   23           Private  122272     Bachelors             13   \n",
       "12   32           Private  205019    Assoc-acdm             12   \n",
       "14   34           Private  245487       7th-8th              4   \n",
       "\n",
       "           marital-status         occupation   relationship  \\\n",
       "0      Married-civ-spouse    Exec-managerial        Husband   \n",
       "1                Divorced  Handlers-cleaners  Not-in-family   \n",
       "2      Married-civ-spouse  Handlers-cleaners        Husband   \n",
       "3      Married-civ-spouse     Prof-specialty           Wife   \n",
       "4      Married-civ-spouse    Exec-managerial           Wife   \n",
       "5   Married-spouse-absent      Other-service  Not-in-family   \n",
       "6      Married-civ-spouse    Exec-managerial        Husband   \n",
       "7           Never-married     Prof-specialty  Not-in-family   \n",
       "8      Married-civ-spouse    Exec-managerial        Husband   \n",
       "9      Married-civ-spouse    Exec-managerial        Husband   \n",
       "10     Married-civ-spouse     Prof-specialty        Husband   \n",
       "11          Never-married       Adm-clerical      Own-child   \n",
       "12          Never-married              Sales  Not-in-family   \n",
       "14     Married-civ-spouse   Transport-moving        Husband   \n",
       "\n",
       "                  race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                White    Male             0             0              13   \n",
       "1                White    Male             0             0              40   \n",
       "2                Black    Male             0             0              40   \n",
       "3                Black  Female             0             0              40   \n",
       "4                White  Female             0             0              40   \n",
       "5                Black  Female             0             0              16   \n",
       "6                White    Male             0             0              45   \n",
       "7                White  Female         14084             0              50   \n",
       "8                White    Male          5178             0              40   \n",
       "9                Black    Male             0             0              80   \n",
       "10  Asian-Pac-Islander    Male             0             0              40   \n",
       "11               White  Female             0             0              30   \n",
       "12               Black    Male             0             0              50   \n",
       "14  Amer-Indian-Eskimo    Male             0             0              45   \n",
       "\n",
       "   native-country income  \n",
       "0   United-States  <=50K  \n",
       "1   United-States  <=50K  \n",
       "2   United-States  <=50K  \n",
       "3            Cuba  <=50K  \n",
       "4   United-States  <=50K  \n",
       "5         Jamaica  <=50K  \n",
       "6   United-States   >50K  \n",
       "7   United-States   >50K  \n",
       "8   United-States   >50K  \n",
       "9   United-States   >50K  \n",
       "10          India   >50K  \n",
       "11  United-States  <=50K  \n",
       "12  United-States  <=50K  \n",
       "14         Mexico  <=50K  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_data = cleaned_Data.copy() # make a copy of our cleaned data, creating a new data frame for our categorical encoding\n",
    "encoding_data.head(14) # our first removed sample was at index 13 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da373bb0-f090-49ad-979c-bf03045448ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried implementing mapping but I did not get it entirely correct and I was having NaN values\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html\n",
    "\n",
    "# we also needing to strip all whitespace from category values for this binary encoding\n",
    "\n",
    "# manual binary encoding for just the two categories of the label\n",
    "# here we iterate through each index - sample in our dataframe \n",
    "for index, sample in encoding_data.iterrows():\n",
    "    # if the samples income value is >50k then we change that value to a 1\n",
    "    if sample['income'] == '>50K':\n",
    "        encoding_data.at[index, 'income'] = 1\n",
    "    # if the income value is isntead <=50k then we change that value to a 0\n",
    "    elif sample['income'] == '<=50K':\n",
    "        encoding_data.at[index, 'income'] = 0\n",
    "    # we need to change the datatype to int for the column now that all the values are now all numerical binary values\n",
    "encoding_data['income'] = encoding_data['income'].astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3181274d-5d16-45f0-abb1-ab9fb81b9952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_data[\"income\"].isna().sum()  # all samples have a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d2088ba-38ad-4cdc-b391-6ebf5c41a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "32555    0\n",
       "32556    1\n",
       "32557    0\n",
       "32558    0\n",
       "32559    1\n",
       "Name: income, Length: 30161, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_data['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de4b3746-361b-4613-9c3d-fc15d643812b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "0    22653\n",
       "1     7508\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_data['income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "646fa4f4-033c-4b7f-8fd0-7f0726b9df90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "<=50K    22653\n",
       ">50K      7508\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_Data['income'].value_counts()\n",
    "# we see that the value coutns align so our encoding was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af54ee19-eb07-47a7-b254-bfa310f44caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_data = encoding_data.copy() # here we make a copy of our data at this point for one of our two sklearn implementations below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8b1d8e1-3cb5-44d2-958d-98d9df8d881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this encoding worked as the income categories were assigned the correct binary values\n",
    "# I checked with encoding_data.tail() and cleaned_Data.tail() and the values align with our new encoded income feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2656f472-84f7-4544-8a11-9386caec5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector for each sample for that categorical value\n",
    "# fill it with zeros, and then append a 1 if for the categorical value the samples value was equal to that column value, if not leave the zero\n",
    "# This was an implementation I had done before in pytorch but it wasn't the best approach here, so I am going with something different\n",
    "\n",
    "\n",
    "# not sure if we can use sklearn encoding or pandas dummy encoding\n",
    "# I am not sure one hot is the best for this because of the added features making the # of features more sparse, icnrease from 15 to 105 features\n",
    "# But I know that one-hot is the most common encoding even with making features sparse and it is typically used unless categories are ordinal\n",
    "\n",
    "\n",
    "# here is my implementation of one_hot encoding\n",
    "def one_hot (encoding_data, current_col):\n",
    "    replacement_one_hot_cols = pd.DataFrame(index = encoding_data.index) # create a dataframe with the indices from our existing dataframe\n",
    "\n",
    "    categories = encoding_data[current_col].unique() # np array of unique values in the current column \n",
    "    \n",
    "    for category in categories: # for each unique category in our array of categories\n",
    "        print(current_col, \"-\", category) # I print our each unique category in our array of categories, original col + the unique category ( our new category names will have a similar structure)\n",
    "        new_col_name = f\"{current_col}_{category}\" # new col name is a format string of the original col name _ the value category\n",
    "        replacement_one_hot_cols[new_col_name] = (encoding_data[current_col] == category).astype(int) \n",
    "        # we create a new col with the new_col_name as the feature name\n",
    "        # for the value we compare values of our encoding_data[current_col] with the current unique category we are accessing\n",
    "        # for each sample with a value = to the unique category we are currently creating a new column for\n",
    "        # then we assign a 1 to that sample in our new column, if it does not match our current category \n",
    "        # then we assign a 0\n",
    "        \n",
    "    return replacement_one_hot_cols #return the new col to add to the dataframe\n",
    "    # with this encoding method, we create a new col for each unique category in the column we pass in\n",
    "    # the binary values of each new column need to correspond to the original categorical value\n",
    "    # so for col sex, there are 2 unique categories in our dataset, male and female\n",
    "    # when we create the new col sex_male, we should assign 1's to the samples that used to have male as the categorical value and 0 to the samples\n",
    "    # that had female as the original categorical value \n",
    "    # then when we create sex_female, all of the samples whos original samples were female will be assigned a 1 and male will get a 0 in this new column\n",
    "\n",
    "    # we call this function for each categorical feature column of our existing dataframe, we return one new column for each unique category in the \n",
    "    # feature column with a format string name, and binary values that correspond to the new col and the original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e09a4338-c45f-4973-a0bd-e6c6b5c2fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass - Self-emp-not-inc\n",
      "workclass - Private\n",
      "workclass - State-gov\n",
      "workclass - Federal-gov\n",
      "workclass - Local-gov\n",
      "workclass - Self-emp-inc\n",
      "workclass - Without-pay\n",
      "education - Bachelors\n",
      "education - HS-grad\n",
      "education - 11th\n",
      "education - Masters\n",
      "education - 9th\n",
      "education - Some-college\n",
      "education - Assoc-acdm\n",
      "education - 7th-8th\n",
      "education - Doctorate\n",
      "education - Assoc-voc\n",
      "education - Prof-school\n",
      "education - 5th-6th\n",
      "education - 10th\n",
      "education - Preschool\n",
      "education - 12th\n",
      "education - 1st-4th\n",
      "marital-status - Married-civ-spouse\n",
      "marital-status - Divorced\n",
      "marital-status - Married-spouse-absent\n",
      "marital-status - Never-married\n",
      "marital-status - Separated\n",
      "marital-status - Married-AF-spouse\n",
      "marital-status - Widowed\n",
      "occupation - Exec-managerial\n",
      "occupation - Handlers-cleaners\n",
      "occupation - Prof-specialty\n",
      "occupation - Other-service\n",
      "occupation - Adm-clerical\n",
      "occupation - Sales\n",
      "occupation - Transport-moving\n",
      "occupation - Farming-fishing\n",
      "occupation - Machine-op-inspct\n",
      "occupation - Tech-support\n",
      "occupation - Craft-repair\n",
      "occupation - Protective-serv\n",
      "occupation - Armed-Forces\n",
      "occupation - Priv-house-serv\n",
      "relationship - Husband\n",
      "relationship - Not-in-family\n",
      "relationship - Wife\n",
      "relationship - Own-child\n",
      "relationship - Unmarried\n",
      "relationship - Other-relative\n",
      "race - White\n",
      "race - Black\n",
      "race - Asian-Pac-Islander\n",
      "race - Amer-Indian-Eskimo\n",
      "race - Other\n",
      "sex - Male\n",
      "sex - Female\n",
      "native-country - United-States\n",
      "native-country - Cuba\n",
      "native-country - Jamaica\n",
      "native-country - India\n",
      "native-country - Mexico\n",
      "native-country - Puerto-Rico\n",
      "native-country - Honduras\n",
      "native-country - England\n",
      "native-country - Canada\n",
      "native-country - Germany\n",
      "native-country - Iran\n",
      "native-country - Philippines\n",
      "native-country - Poland\n",
      "native-country - Columbia\n",
      "native-country - Cambodia\n",
      "native-country - Thailand\n",
      "native-country - Ecuador\n",
      "native-country - Laos\n",
      "native-country - Taiwan\n",
      "native-country - Haiti\n",
      "native-country - Portugal\n",
      "native-country - Dominican-Republic\n",
      "native-country - El-Salvador\n",
      "native-country - France\n",
      "native-country - Guatemala\n",
      "native-country - Italy\n",
      "native-country - China\n",
      "native-country - South\n",
      "native-country - Japan\n",
      "native-country - Yugoslavia\n",
      "native-country - Peru\n",
      "native-country - Outlying-US(Guam-USVI-etc)\n",
      "native-country - Scotland\n",
      "native-country - Trinadad&Tobago\n",
      "native-country - Greece\n",
      "native-country - Nicaragua\n",
      "native-country - Vietnam\n",
      "native-country - Hong\n",
      "native-country - Ireland\n",
      "native-country - Hungary\n",
      "native-country - Holand-Netherlands\n"
     ]
    }
   ],
   "source": [
    "# for each col in our current working dataframe\n",
    "for col in encoding_data.columns:\n",
    "    current_data_type = encoding_data[col].dtype # determine the datatype of each column, like we did above\n",
    "    if current_data_type != 'int64' and current_data_type != 'float64': # if it is not a numerical feature column \n",
    "        add_these = one_hot(encoding_data, col) # create a new set of feature columns for each categorical value in this categorical feature col\n",
    "\n",
    "        # before we move to the next column we concatenate our new binary columns that represent each category in our categorical feature column\n",
    "        # with the starting dataframe, encoding_data\n",
    "        encoding_data = pd.concat([encoding_data, add_these], axis = 1) # make it remove the current col and add the news ones in the same place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3166d61-0295-4323-adde-3cc313dd5371",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_column_name = 'income'\n",
    "cols_categorical.remove(label_column_name)\n",
    "# remove 'income', our label column from our list of categorical columns\n",
    "# it was changed to a numerical column and no longer belongs in the list of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "944d1c83-9ba5-495e-bcc5-b375531f527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_data = encoding_data.drop(cols_categorical, axis=1) # then we drop all of the original categorical columns from our dataframe\n",
    "# now that each category from each categorical feature column is now represented by its own binary numerical col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e236efc3-b96d-4e96-a455-61dc3d8f849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in encoding_data.columns:\n",
    "#     print(encoding_data[col].value_counts())\n",
    "# we can see the new value counts of our now 105 col dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5616b0c-012a-4577-a52c-2aebdff30a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in encoding_data.columns:\n",
    "#     current_data_type = encoding_data[col].dtype\n",
    "#     print(col,':',current_data_type)\n",
    "\n",
    "# this was to specfically print our all the names of our new dataframe cols and the associated column datatype to make sure all categorical\n",
    "# columns were removed and all of the new columns are numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd666e2a-624a-4db1-94f9-a794337c51a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_data.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65288732-1e6b-4e62-8aaa-8440e01072bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Outlying-US(Guam-USVI-etc)</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_Greece</th>\n",
       "      <th>native-country_Nicaragua</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Hong</th>\n",
       "      <th>native-country_Ireland</th>\n",
       "      <th>native-country_Hungary</th>\n",
       "      <th>native-country_Holand-Netherlands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>27</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>40</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>58</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>22</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>52</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "32555   27  257302             12             0             0              38   \n",
       "32556   40  154374              9             0             0              40   \n",
       "32557   58  151910              9             0             0              40   \n",
       "32558   22  201490              9             0             0              20   \n",
       "32559   52  287927              9         15024             0              40   \n",
       "\n",
       "       income  workclass_Self-emp-not-inc  workclass_Private  \\\n",
       "32555       0                           0                  1   \n",
       "32556       1                           0                  1   \n",
       "32557       0                           0                  1   \n",
       "32558       0                           0                  1   \n",
       "32559       1                           0                  0   \n",
       "\n",
       "       workclass_State-gov  ...  native-country_Outlying-US(Guam-USVI-etc)  \\\n",
       "32555                    0  ...                                          0   \n",
       "32556                    0  ...                                          0   \n",
       "32557                    0  ...                                          0   \n",
       "32558                    0  ...                                          0   \n",
       "32559                    0  ...                                          0   \n",
       "\n",
       "       native-country_Scotland  native-country_Trinadad&Tobago  \\\n",
       "32555                        0                               0   \n",
       "32556                        0                               0   \n",
       "32557                        0                               0   \n",
       "32558                        0                               0   \n",
       "32559                        0                               0   \n",
       "\n",
       "       native-country_Greece  native-country_Nicaragua  \\\n",
       "32555                      0                         0   \n",
       "32556                      0                         0   \n",
       "32557                      0                         0   \n",
       "32558                      0                         0   \n",
       "32559                      0                         0   \n",
       "\n",
       "       native-country_Vietnam  native-country_Hong  native-country_Ireland  \\\n",
       "32555                       0                    0                       0   \n",
       "32556                       0                    0                       0   \n",
       "32557                       0                    0                       0   \n",
       "32558                       0                    0                       0   \n",
       "32559                       0                    0                       0   \n",
       "\n",
       "       native-country_Hungary  native-country_Holand-Netherlands  \n",
       "32555                       0                                  0  \n",
       "32556                       0                                  0  \n",
       "32557                       0                                  0  \n",
       "32558                       0                                  0  \n",
       "32559                       0                                  0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60461aa2-f3c2-4281-b396-e4c60e331505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ffb3ecb-afcb-42d2-999f-7058832acb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22653 less than 50k\n",
    "#7508 more than 50k - \n",
    "# here is my implementation of train_test split\n",
    "\n",
    "\n",
    "\n",
    "# we need to pass in our default rng, the data we want split into training and testing datasets, the percentage of the data to preserve for testing\n",
    "# and the label column name to make sure we take a balanced percentage of samples from each of label values\n",
    "def kelton_train_test_split (data, label_column_name, rng, test_size = 0.3):\n",
    "\n",
    "    # here we apply a boolean mask to the dataframe that we pass in to find specific sample values\n",
    "    # label_true is a dataframe resulting from applying a mask to our original dataframe and retreiving only the samples whos \n",
    "    # label_column_name value is equal to 1 which is the binary value for >50k income\n",
    "    # label false is then a dataframe of samples where the income col is 0 or <=50k income\n",
    "    label_true = data[data[label_column_name] == 1]#.reset_index(drop=True)\n",
    "    label_false = data[data[label_column_name] == 0]#.reset_index(drop=True)\n",
    "\n",
    "    # these are variables to limit the amount of samples that we take from each dataframe that\n",
    "    # hold the respective samples of income >50k and income <=50k\n",
    "    # we want to take 30% of the each of the datasets for our testing dataset and leave 70% for testing\n",
    "    # this is to stratify the samples that we take from each label class to make sure testing and training percentages are balanced by %\n",
    "    test_sample_size_true = int(test_size * len(label_true)) # test size is a float, evaluate what test_size proportion of each dataframe is\n",
    "    test_sample_size_false = int(test_size * len(label_false)) # each dataframe holds a different class of label values\n",
    "\n",
    "\n",
    "    # here we need to randomly choose 30% or whatever % of each of our label class dataframe samples without replacement, we don't want duplicates\n",
    "    # rng.choice(choosing a position from len(label_true or label_false), # of samples to randomly choose, no replacement)\n",
    "    # with rng.choice we need to use iloc not loc because with loc we would need to reset the indicies above for each of our class specific dataframes\n",
    "    # in my implementation I use .iloc as it doesn't require the exact index but whatever number is generated from 0 to len(label_true/false)\n",
    "    # it gets the iloc will retrieve the positional sample in the dataframe whereas .loc would try to access the sample at that index\n",
    "    # so for both the true and false label class dataframes we use our test sample size variables to then randomly select that many samples\n",
    "    # from each class label dataframe, this makes sure we have randomly chosen a stratified sample from our original dataset for our testing set\n",
    "    test_true_label = label_true.iloc[rng.choice(len(label_true), test_sample_size_true, replace = False)]\n",
    "    test_false_label = label_false.iloc[rng.choice(len(label_false), test_sample_size_false, replace = False)]\n",
    "\n",
    "    # this is simpler, now that we have randomly chosen out a test_size proportion of our dataset for testing, we simply need to the\n",
    "    # indices from the resulting testing dataframes from our label class datadrames which will leave us with the remaining samples for training\n",
    "    train_true_label = label_true.drop(test_true_label.index) # drop label class 1 test indices- resulting can be used for training\n",
    "    train_false_label = label_false.drop(test_false_label.index) # drop label class 0 test indices\n",
    "\n",
    "    # https://www.geeksforgeeks.org/pandas-how-to-shuffle-a-dataframe-rows/\n",
    "    # this should shuffle and then reset indices\n",
    "    # to get our train and test datasets now we need to concat the two label class dataframes for each testing and training back together\n",
    "\n",
    "    #.sample(frac=1) should shuffle the data and return 100% of it, then we reset the indices of each \n",
    "    train_data = pd.concat([train_true_label, train_false_label]).sample(frac = 1).reset_index(drop=True)\n",
    "    test_data = pd.concat([test_true_label, test_false_label]).sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "    # I believe you can use .sample as another method for randomly selecting samples from a dataframe as it also has a replace = true/false parameter\n",
    "    return train_data, test_data # return both the training and testing datasets for our model\n",
    "    \n",
    "# data_sample = data.sample(n=10000, random_state=student_number_last_four_digits).reset_index(drop=True)\n",
    "# your code from assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c64d69e1-5a9a-47c6-91ca-4bff8503f254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Outlying-US(Guam-USVI-etc)</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_Greece</th>\n",
       "      <th>native-country_Nicaragua</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Hong</th>\n",
       "      <th>native-country_Ireland</th>\n",
       "      <th>native-country_Hungary</th>\n",
       "      <th>native-country_Holand-Netherlands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21109</th>\n",
       "      <td>43</td>\n",
       "      <td>147110</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21110</th>\n",
       "      <td>50</td>\n",
       "      <td>190333</td>\n",
       "      <td>15</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21111</th>\n",
       "      <td>27</td>\n",
       "      <td>46868</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21112</th>\n",
       "      <td>45</td>\n",
       "      <td>285335</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21113</th>\n",
       "      <td>74</td>\n",
       "      <td>39890</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "21109   43  147110             10             0             0              48   \n",
       "21110   50  190333             15         99999             0              55   \n",
       "21111   27   46868             13             0             0              15   \n",
       "21112   45  285335              4             0             0              10   \n",
       "21113   74   39890             10             0             0              18   \n",
       "\n",
       "       income  workclass_Self-emp-not-inc  workclass_Private  \\\n",
       "21109       1                           0                  1   \n",
       "21110       1                           0                  0   \n",
       "21111       0                           0                  1   \n",
       "21112       0                           1                  0   \n",
       "21113       0                           0                  0   \n",
       "\n",
       "       workclass_State-gov  ...  native-country_Outlying-US(Guam-USVI-etc)  \\\n",
       "21109                    0  ...                                          0   \n",
       "21110                    0  ...                                          0   \n",
       "21111                    0  ...                                          0   \n",
       "21112                    0  ...                                          0   \n",
       "21113                    0  ...                                          0   \n",
       "\n",
       "       native-country_Scotland  native-country_Trinadad&Tobago  \\\n",
       "21109                        0                               0   \n",
       "21110                        0                               0   \n",
       "21111                        0                               0   \n",
       "21112                        0                               0   \n",
       "21113                        0                               0   \n",
       "\n",
       "       native-country_Greece  native-country_Nicaragua  \\\n",
       "21109                      0                         0   \n",
       "21110                      0                         0   \n",
       "21111                      0                         0   \n",
       "21112                      0                         0   \n",
       "21113                      0                         0   \n",
       "\n",
       "       native-country_Vietnam  native-country_Hong  native-country_Ireland  \\\n",
       "21109                       0                    0                       0   \n",
       "21110                       0                    0                       0   \n",
       "21111                       0                    0                       0   \n",
       "21112                       0                    0                       0   \n",
       "21113                       0                    0                       0   \n",
       "\n",
       "       native-country_Hungary  native-country_Holand-Netherlands  \n",
       "21109                       0                                  0  \n",
       "21110                       0                                  0  \n",
       "21111                       0                                  0  \n",
       "21112                       0                                  0  \n",
       "21113                       0                                  0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = kelton_train_test_split (encoding_data, 'income' , rng, test_size = 0.3) \n",
    "# here we pass in our data, the label column name, our rng from default.rng that we initialize with our imports ( I set my to 1995) and \n",
    "# we can declare the % of data to allot to our testing dataset, I chose 30%\n",
    "train_data.tail(5)\n",
    "\n",
    "# check value counts for our new training only dataframe training set\n",
    "# for col in train_data.columns:\n",
    "#     print(train_data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41614231-08d6-4659-8fd2-7dba1f9018c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Outlying-US(Guam-USVI-etc)</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_Greece</th>\n",
       "      <th>native-country_Nicaragua</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Hong</th>\n",
       "      <th>native-country_Ireland</th>\n",
       "      <th>native-country_Hungary</th>\n",
       "      <th>native-country_Holand-Netherlands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>20</td>\n",
       "      <td>34706</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>41</td>\n",
       "      <td>118853</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9044</th>\n",
       "      <td>18</td>\n",
       "      <td>362600</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9045</th>\n",
       "      <td>45</td>\n",
       "      <td>151627</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9046</th>\n",
       "      <td>37</td>\n",
       "      <td>179731</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "9042   20   34706             10             0             0              47   \n",
       "9043   41  118853             10             0             0              40   \n",
       "9044   18  362600              3             0             0              40   \n",
       "9045   45  151627             10             0             0              45   \n",
       "9046   37  179731              9             0             0              35   \n",
       "\n",
       "      income  workclass_Self-emp-not-inc  workclass_Private  \\\n",
       "9042       0                           0                  1   \n",
       "9043       0                           0                  1   \n",
       "9044       0                           0                  1   \n",
       "9045       0                           0                  1   \n",
       "9046       0                           0                  1   \n",
       "\n",
       "      workclass_State-gov  ...  native-country_Outlying-US(Guam-USVI-etc)  \\\n",
       "9042                    0  ...                                          0   \n",
       "9043                    0  ...                                          0   \n",
       "9044                    0  ...                                          0   \n",
       "9045                    0  ...                                          0   \n",
       "9046                    0  ...                                          0   \n",
       "\n",
       "      native-country_Scotland  native-country_Trinadad&Tobago  \\\n",
       "9042                        0                               0   \n",
       "9043                        0                               0   \n",
       "9044                        0                               0   \n",
       "9045                        0                               0   \n",
       "9046                        0                               0   \n",
       "\n",
       "      native-country_Greece  native-country_Nicaragua  native-country_Vietnam  \\\n",
       "9042                      0                         0                       0   \n",
       "9043                      0                         0                       0   \n",
       "9044                      0                         0                       0   \n",
       "9045                      0                         0                       0   \n",
       "9046                      0                         0                       0   \n",
       "\n",
       "      native-country_Hong  native-country_Ireland  native-country_Hungary  \\\n",
       "9042                    0                       0                       0   \n",
       "9043                    0                       0                       0   \n",
       "9044                    0                       0                       0   \n",
       "9045                    0                       0                       0   \n",
       "9046                    0                       0                       0   \n",
       "\n",
       "      native-country_Holand-Netherlands  \n",
       "9042                                  0  \n",
       "9043                                  0  \n",
       "9044                                  0  \n",
       "9045                                  0  \n",
       "9046                                  0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e060b5-73a4-4bb4-9b22-8a8aabd62031",
   "metadata": {},
   "source": [
    "# Lab 1/2 Code & Changes for RF Classifier From Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24c30e24-6d87-41ee-a53c-aa6f047ae53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 3.0 7.0\n"
     ]
    }
   ],
   "source": [
    "#Assignment 2 function\n",
    "# I am calculating how many times I can \"perfectly\" divide a node to stay above a certain number of leaf node samples\n",
    "# this will tell us with a given min_lead_node_samples what our max depth would be for that number of min leaf samples\n",
    "\n",
    "def sample_information (num_samples):\n",
    "    depth_counter = 0\n",
    "    resulting = 3 # this results in a min leaf node of 3 for this current data\n",
    "    # to make it stay above 5, or any x number declared, I would need to keep track of the previous iteration in the while loop\n",
    "    # because it doesn't check the condition until after the division has already occured\n",
    "    calcd_resulting = num_samples\n",
    "    while (calcd_resulting > resulting):\n",
    "        depth_counter+=1\n",
    "        calcd_resulting = np.ceil(calcd_resulting / 2) #int division \"//\" would do floor\n",
    "\n",
    "    return depth_counter, calcd_resulting\n",
    "\n",
    "\n",
    "\n",
    "#hyper parameters\n",
    "label_col_name = 'income'\n",
    "num_trees_in_forest = 111\n",
    "num_random_features = int(np.ceil(np.sqrt(train_data.shape[1]) * 2)) # we had a very large feature increase from one-hot / dummy encoding\n",
    "# I know it is common to use sqrt or log2 the number of features, I am testing with using more as the featureset is more sparse now\n",
    "\n",
    "\n",
    "\n",
    "depth_threshold, split_leaf_minimum = sample_information(train_data.shape[0]) # \n",
    "split_node_min_samples = (split_leaf_minimum * 2) + 1 # you need at least 2x the leaf_node_samples in the parent node to split and\n",
    "# and maintain the minimum samples in the leaf\n",
    "\n",
    "\n",
    "\n",
    "print(depth_threshold, split_leaf_minimum, split_node_min_samples)\n",
    "# i think i read 6-7 depth is a lot\n",
    "\n",
    "# how many combinations of num random features are possible, so how many times within the num trees in forest will there be duplicates?\n",
    "# how many duplicates would be good mathematically or are any good at all?\n",
    "# 105 choose 21 is 6.3864156e+21, so what % of this do we want for num trees in forest? \n",
    "# the likelhood you get two of the same trees in a forest is low and would require an astronomical number of trees\n",
    "\n",
    "#with these settings, we could \"perfectly\" split 13 times down to a depth of 13 and a resulting leaf nodes of 3, I won't make the tree depth that deep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdcc5a01-ba19-4955-8678-b260c83fb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this function I am taking in the training dataset, the label and the total number of train samples\n",
    "# for each training sample in the dataset we randomly grab a row from the training dataset to create our bootstrap dataset\n",
    "# so in our case we have a training dataset of 8500, so we create a bootstrap that has 8500 samples from our original train dataset\n",
    "# we get indices to pull from the training set randomly by generating a random # from 0 to 8499 and adding that row to our array\n",
    "# once we have created our array of samples from the rows of the training dataset, we create the bootstrap dataset from our array of rows\n",
    "# this method will allow duplicates, and with this many samples we should end up with roughly 65% of the train dataset in our bootstrap\n",
    "# then we seperate the label column from the X_bootstrap resulting in just the training data with no label\n",
    "# then y_bootstrap is just the labels column, but all of the indices match up\n",
    "\n",
    "\n",
    "# -------- new ----------\n",
    "# now I need to make sure that we are taking a balanced sample from the training datatset\n",
    "# in my dataset we have 3x more 0's in the label feature than 1's\n",
    "# so total samples needs to be for each category, so len(income == 1) samples\n",
    "# take that many samples with a 1 and that many samples with a 0 as the income category\n",
    "def bootstrap_creator(this_tree_data, label_column_name):\n",
    "\n",
    "  # -------- new ----------\n",
    "  # classifier specific balancing\n",
    "  # we need to make sure that we take a balanced sample for each bootstrap, we want to train with a similar number of label classes\n",
    "  # so again we split the dataframe into one for each label class\n",
    "  category_label_0 = this_tree_data[this_tree_data[label_column_name] == 0]\n",
    "  category_label_1 = this_tree_data[this_tree_data[label_column_name] == 1]\n",
    "\n",
    "\n",
    "  # this variable finds which label class dataframe has the least number of samples\n",
    "  # by calculating this minimum we know how many samples we want to choose from each label dataframe\n",
    "  samples_from_each = min(len(category_label_0), len(category_label_1))\n",
    "  # in my dataset label 1 is roughly 1/3 the size of label 0\n",
    "  # so to follow bootstrapping methodology we want to randomly sample the len(category_label_1) from each of the label class dataframes)\n",
    "  # so if the lesser dataframe had 3000 samples, we would sample 3000 from both, so that we are training with a 50/50 split of class labels\n",
    "  # we have ~21000 train samples, but we don't randomly select 21000 because it would be highly imbalanced\n",
    "  # so we sample len(category_label_1) from each each label class dataframe and that should result in the same bootstrapping methodology that \n",
    "  # would be used in a regression model\n",
    "  # We are going to get even more varied samples between each decision tree for our label_0 samples\n",
    "  # I contemplated pulling out a sample the size of category_label_1 from label_0 and only using that for bootstrapping\n",
    "  # but I believe that with our training set balancing and and the very varied label 0 samples per tree, that should make the training data more sparse\n",
    "  # which is better and will help with overfitting, whereas it will be more of a problem with our samples for category_label_1\n",
    "    \n",
    "  bootstrap_for_this_tree = [] # holder array for the bootstrap\n",
    "\n",
    "  negative_samples_this_bootstrap = category_label_0.sample(samples_from_each, replace = True)  # here we use .sample to randomly select our bootstraps\n",
    "    # instead of rng.choice or the method we used in assignment 2 by randomly generating indices\n",
    "    # with .sample() we set replace to true as duplicates are allowed in bootstraping and we sample samples_from_each as a hyperparameter \n",
    "    # because that is the size of our lesser category_label_dataframe\n",
    "  positive_samples_this_bootstrap = category_label_1.sample(samples_from_each, replace = True) \n",
    "\n",
    "    #would the opposite methodology be bad? if we took the max and then oversampled category_label_1 / the lesser label_class amount up to the amount \n",
    "    # in the of samples in the larger label class \n",
    "    \n",
    "    # here we concat the two different samples that we drew from the training dataset to pass to our dt builder and feature split selector\n",
    "  bootstrap = pd.concat([positive_samples_this_bootstrap, negative_samples_this_bootstrap], axis = 0)\n",
    "    \n",
    "    # generate X and Y bootstraps from bootstrap\n",
    "  X_bootstrap = bootstrap.drop(label_column_name, axis=1)\n",
    "  y_bootstrap = bootstrap[label_column_name]\n",
    "\n",
    "  return X_bootstrap, y_bootstrap, bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abfefa49-7fd3-4581-81b2-bc583ba467ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I did not need to edit this function from assingment 2 as nothing here changed\n",
    "\n",
    "# this function is used to calculate the rows from the training dataset that did not make it into this bootstrap dataset\n",
    "# we pass in the label, the training dataset and the randomly selected bootstrap dataset\n",
    "# with a dataframe this is a bit simpler than with the all integer numpy array from the class example\n",
    "# here we can simply drop all of the indices (rows) that exist in the bootstrap data set from the training data set and we are left with the out of box sample set\n",
    "# I didn't need to copy the dataframe, I find myself doing this somewhat often when I am working with dataframes to maintain the last version of them\n",
    "# I want to say I picked up this habit during my AI course but I don't remember why exactly, I think it had to do with model evaluations\n",
    "# then to find the data frames for X_oob and y_oob we simply drop the label from our total oob dataframe for X and pull out only the label column for our y\n",
    "\n",
    "def oob_determination(tree_data, bootstrap, label_column_name):\n",
    "\n",
    "    # drop bootstrap rows from the total tree training data set to be left with a dataframe of only the none-selected training samples\n",
    "  oob_for_this_tree = tree_data.drop(index=bootstrap.index) # drop all the indices from the tree dataset/ training dataset that exist within the bootstrap for this specific tree\n",
    "\n",
    "    # copy oob_for_this_tree incase we need to pass it as a return later\n",
    "  all_oob_this_tree = oob_for_this_tree.copy()\n",
    "\n",
    "    # make the X-oob and y_oob respective dataframes\n",
    "  X_oob = oob_for_this_tree.drop(label_column_name, axis=1)\n",
    "  y_oob = oob_for_this_tree[label_column_name]\n",
    "\n",
    "  return X_oob, y_oob, all_oob_this_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de7f3947-8e0e-48d0-917e-88d0761fadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I did not need to edit this function from assingment 2 as nothing here changed\n",
    "\n",
    "#this function calls the bootstrap creation function and then passes the bootstrap dataset into oob to return the oob values\n",
    "# meaning bootstrap + oob below make up the entirety of the 8500 data samples within sample_data_train without any overlap\n",
    "# and this function just returns the output of both lumped together\n",
    "def boot_strap_and_oob(tree_data, label_column_name):\n",
    "  X_bootstrap, y_bootstrap, bootstrap = bootstrap_creator(tree_data, label_column_name)\n",
    "  X_oob, y_oob, all_oob = oob_determination(tree_data, bootstrap, label_column_name)\n",
    "\n",
    "  return X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap, all_oob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d75ec35c-37f7-4447-b458-40588d2fd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration of these functions working correctly with the new sampling method, passing in the the training dataset and retreiving all of the bootstrap & oob data frames\n",
    "def main(data, label_column_name):\n",
    "  X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap, all_oob = boot_strap_and_oob(data, label_column_name)\n",
    "  return X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap, all_oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e28fa17-c7ac-494d-a61d-326a378ebdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap, all_oob = main(train_data, label_column_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb2ae489-094c-4b03-8ed0-c3acfae67758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10512, 105)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2e883d9-71b3-4303-82c0-73609ade7703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Outlying-US(Guam-USVI-etc)</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_Greece</th>\n",
       "      <th>native-country_Nicaragua</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Hong</th>\n",
       "      <th>native-country_Ireland</th>\n",
       "      <th>native-country_Hungary</th>\n",
       "      <th>native-country_Holand-Netherlands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>316688</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>32668</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>32668</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>32668</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>216436</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21103</th>\n",
       "      <td>51</td>\n",
       "      <td>311569</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21107</th>\n",
       "      <td>54</td>\n",
       "      <td>235693</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21109</th>\n",
       "      <td>43</td>\n",
       "      <td>147110</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21110</th>\n",
       "      <td>50</td>\n",
       "      <td>190333</td>\n",
       "      <td>15</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21110</th>\n",
       "      <td>50</td>\n",
       "      <td>190333</td>\n",
       "      <td>15</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10512 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "2       25  316688              9             0             0              40   \n",
       "3       37   32668             13             0             0              43   \n",
       "3       37   32668             13             0             0              43   \n",
       "3       37   32668             13             0             0              43   \n",
       "5       20  216436             13             0             0              30   \n",
       "...    ...     ...            ...           ...           ...             ...   \n",
       "21103   51  311569              9             0             0              40   \n",
       "21107   54  235693              7             0             0              40   \n",
       "21109   43  147110             10             0             0              48   \n",
       "21110   50  190333             15         99999             0              55   \n",
       "21110   50  190333             15         99999             0              55   \n",
       "\n",
       "       income  workclass_Self-emp-not-inc  workclass_Private  \\\n",
       "2           0                           0                  1   \n",
       "3           1                           0                  1   \n",
       "3           1                           0                  1   \n",
       "3           1                           0                  1   \n",
       "5           0                           0                  1   \n",
       "...       ...                         ...                ...   \n",
       "21103       0                           1                  0   \n",
       "21107       1                           0                  1   \n",
       "21109       1                           0                  1   \n",
       "21110       1                           0                  0   \n",
       "21110       1                           0                  0   \n",
       "\n",
       "       workclass_State-gov  ...  native-country_Outlying-US(Guam-USVI-etc)  \\\n",
       "2                        0  ...                                          0   \n",
       "3                        0  ...                                          0   \n",
       "3                        0  ...                                          0   \n",
       "3                        0  ...                                          0   \n",
       "5                        0  ...                                          0   \n",
       "...                    ...  ...                                        ...   \n",
       "21103                    0  ...                                          0   \n",
       "21107                    0  ...                                          0   \n",
       "21109                    0  ...                                          0   \n",
       "21110                    0  ...                                          0   \n",
       "21110                    0  ...                                          0   \n",
       "\n",
       "       native-country_Scotland  native-country_Trinadad&Tobago  \\\n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "3                            0                               0   \n",
       "3                            0                               0   \n",
       "5                            0                               0   \n",
       "...                        ...                             ...   \n",
       "21103                        0                               0   \n",
       "21107                        0                               0   \n",
       "21109                        0                               0   \n",
       "21110                        0                               0   \n",
       "21110                        0                               0   \n",
       "\n",
       "       native-country_Greece  native-country_Nicaragua  \\\n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "3                          0                         0   \n",
       "3                          0                         0   \n",
       "5                          0                         0   \n",
       "...                      ...                       ...   \n",
       "21103                      0                         0   \n",
       "21107                      0                         0   \n",
       "21109                      0                         0   \n",
       "21110                      0                         0   \n",
       "21110                      0                         0   \n",
       "\n",
       "       native-country_Vietnam  native-country_Hong  native-country_Ireland  \\\n",
       "2                           0                    0                       0   \n",
       "3                           0                    0                       0   \n",
       "3                           0                    0                       0   \n",
       "3                           0                    0                       0   \n",
       "5                           0                    0                       0   \n",
       "...                       ...                  ...                     ...   \n",
       "21103                       0                    0                       0   \n",
       "21107                       0                    0                       0   \n",
       "21109                       0                    0                       0   \n",
       "21110                       0                    0                       0   \n",
       "21110                       0                    0                       0   \n",
       "\n",
       "       native-country_Hungary  native-country_Holand-Netherlands  \n",
       "2                           0                                  0  \n",
       "3                           0                                  0  \n",
       "3                           0                                  0  \n",
       "3                           0                                  0  \n",
       "5                           0                                  0  \n",
       "...                       ...                                ...  \n",
       "21103                       0                                  0  \n",
       "21107                       0                                  0  \n",
       "21109                       0                                  0  \n",
       "21110                       0                                  0  \n",
       "21110                       0                                  0  \n",
       "\n",
       "[10512 rows x 105 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19b17b27-2182-4c2a-b087-dd02669f08f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Outlying-US(Guam-USVI-etc)</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_Greece</th>\n",
       "      <th>native-country_Nicaragua</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Hong</th>\n",
       "      <th>native-country_Ireland</th>\n",
       "      <th>native-country_Hungary</th>\n",
       "      <th>native-country_Holand-Netherlands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>316688</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>32668</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>216436</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43</td>\n",
       "      <td>147328</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>171676</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1741</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21099</th>\n",
       "      <td>37</td>\n",
       "      <td>196529</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21103</th>\n",
       "      <td>51</td>\n",
       "      <td>311569</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21107</th>\n",
       "      <td>54</td>\n",
       "      <td>235693</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21109</th>\n",
       "      <td>43</td>\n",
       "      <td>147110</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21110</th>\n",
       "      <td>50</td>\n",
       "      <td>190333</td>\n",
       "      <td>15</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7722 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "2       25  316688              9             0             0              40   \n",
       "3       37   32668             13             0             0              43   \n",
       "5       20  216436             13             0             0              30   \n",
       "8       43  147328             14             0          1977              60   \n",
       "9       36  171676             13             0          1741              40   \n",
       "...    ...     ...            ...           ...           ...             ...   \n",
       "21099   37  196529             14             0             0              45   \n",
       "21103   51  311569              9             0             0              40   \n",
       "21107   54  235693              7             0             0              40   \n",
       "21109   43  147110             10             0             0              48   \n",
       "21110   50  190333             15         99999             0              55   \n",
       "\n",
       "       income  workclass_Self-emp-not-inc  workclass_Private  \\\n",
       "2           0                           0                  1   \n",
       "3           1                           0                  1   \n",
       "5           0                           0                  1   \n",
       "8           1                           0                  0   \n",
       "9           0                           0                  1   \n",
       "...       ...                         ...                ...   \n",
       "21099       1                           0                  0   \n",
       "21103       0                           1                  0   \n",
       "21107       1                           0                  1   \n",
       "21109       1                           0                  1   \n",
       "21110       1                           0                  0   \n",
       "\n",
       "       workclass_State-gov  ...  native-country_Outlying-US(Guam-USVI-etc)  \\\n",
       "2                        0  ...                                          0   \n",
       "3                        0  ...                                          0   \n",
       "5                        0  ...                                          0   \n",
       "8                        0  ...                                          0   \n",
       "9                        0  ...                                          0   \n",
       "...                    ...  ...                                        ...   \n",
       "21099                    0  ...                                          0   \n",
       "21103                    0  ...                                          0   \n",
       "21107                    0  ...                                          0   \n",
       "21109                    0  ...                                          0   \n",
       "21110                    0  ...                                          0   \n",
       "\n",
       "       native-country_Scotland  native-country_Trinadad&Tobago  \\\n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "5                            0                               0   \n",
       "8                            0                               0   \n",
       "9                            0                               0   \n",
       "...                        ...                             ...   \n",
       "21099                        0                               0   \n",
       "21103                        0                               0   \n",
       "21107                        0                               0   \n",
       "21109                        0                               0   \n",
       "21110                        0                               0   \n",
       "\n",
       "       native-country_Greece  native-country_Nicaragua  \\\n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "5                          0                         0   \n",
       "8                          0                         0   \n",
       "9                          0                         0   \n",
       "...                      ...                       ...   \n",
       "21099                      0                         0   \n",
       "21103                      0                         0   \n",
       "21107                      0                         0   \n",
       "21109                      0                         0   \n",
       "21110                      0                         0   \n",
       "\n",
       "       native-country_Vietnam  native-country_Hong  native-country_Ireland  \\\n",
       "2                           0                    0                       0   \n",
       "3                           0                    0                       0   \n",
       "5                           0                    0                       0   \n",
       "8                           0                    0                       0   \n",
       "9                           0                    0                       0   \n",
       "...                       ...                  ...                     ...   \n",
       "21099                       0                    0                       0   \n",
       "21103                       0                    0                       0   \n",
       "21107                       0                    0                       0   \n",
       "21109                       0                    0                       0   \n",
       "21110                       0                    0                       0   \n",
       "\n",
       "       native-country_Hungary  native-country_Holand-Netherlands  \n",
       "2                           0                                  0  \n",
       "3                           0                                  0  \n",
       "5                           0                                  0  \n",
       "8                           0                                  0  \n",
       "9                           0                                  0  \n",
       "...                       ...                                ...  \n",
       "21099                       0                                  0  \n",
       "21103                       0                                  0  \n",
       "21107                       0                                  0  \n",
       "21109                       0                                  0  \n",
       "21110                       0                                  0  \n",
       "\n",
       "[7722 rows x 105 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap.drop_duplicates().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f8e14a6-a5f2-4d97-99b0-1bae5d3cdf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Outlying-US(Guam-USVI-etc)</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_Greece</th>\n",
       "      <th>native-country_Nicaragua</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Hong</th>\n",
       "      <th>native-country_Ireland</th>\n",
       "      <th>native-country_Hungary</th>\n",
       "      <th>native-country_Holand-Netherlands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>43348</td>\n",
       "      <td>16</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>234286</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>144064</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>148294</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>236543</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21106</th>\n",
       "      <td>23</td>\n",
       "      <td>176486</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21108</th>\n",
       "      <td>47</td>\n",
       "      <td>256866</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21111</th>\n",
       "      <td>27</td>\n",
       "      <td>46868</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21112</th>\n",
       "      <td>45</td>\n",
       "      <td>285335</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21113</th>\n",
       "      <td>74</td>\n",
       "      <td>39890</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13384 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0       49   43348             16         99999             0              70   \n",
       "1       52  234286              9         15024             0              40   \n",
       "4       31  144064             10             0             0              40   \n",
       "6       20  148294             10             0             0              40   \n",
       "7       32  236543              8             0             0              40   \n",
       "...    ...     ...            ...           ...           ...             ...   \n",
       "21106   23  176486             10             0             0              25   \n",
       "21108   47  256866              9             0             0              48   \n",
       "21111   27   46868             13             0             0              15   \n",
       "21112   45  285335              4             0             0              10   \n",
       "21113   74   39890             10             0             0              18   \n",
       "\n",
       "       income  workclass_Self-emp-not-inc  workclass_Private  \\\n",
       "0           1                           1                  0   \n",
       "1           1                           0                  0   \n",
       "4           0                           0                  1   \n",
       "6           0                           0                  1   \n",
       "7           0                           0                  1   \n",
       "...       ...                         ...                ...   \n",
       "21106       0                           0                  1   \n",
       "21108       0                           0                  1   \n",
       "21111       0                           0                  1   \n",
       "21112       0                           1                  0   \n",
       "21113       0                           0                  0   \n",
       "\n",
       "       workclass_State-gov  ...  native-country_Outlying-US(Guam-USVI-etc)  \\\n",
       "0                        0  ...                                          0   \n",
       "1                        0  ...                                          0   \n",
       "4                        0  ...                                          0   \n",
       "6                        0  ...                                          0   \n",
       "7                        0  ...                                          0   \n",
       "...                    ...  ...                                        ...   \n",
       "21106                    0  ...                                          0   \n",
       "21108                    0  ...                                          0   \n",
       "21111                    0  ...                                          0   \n",
       "21112                    0  ...                                          0   \n",
       "21113                    0  ...                                          0   \n",
       "\n",
       "       native-country_Scotland  native-country_Trinadad&Tobago  \\\n",
       "0                            0                               0   \n",
       "1                            0                               0   \n",
       "4                            0                               0   \n",
       "6                            0                               0   \n",
       "7                            0                               0   \n",
       "...                        ...                             ...   \n",
       "21106                        0                               0   \n",
       "21108                        0                               0   \n",
       "21111                        0                               0   \n",
       "21112                        0                               0   \n",
       "21113                        0                               0   \n",
       "\n",
       "       native-country_Greece  native-country_Nicaragua  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "4                          0                         0   \n",
       "6                          0                         0   \n",
       "7                          0                         0   \n",
       "...                      ...                       ...   \n",
       "21106                      0                         0   \n",
       "21108                      0                         0   \n",
       "21111                      0                         0   \n",
       "21112                      0                         0   \n",
       "21113                      0                         0   \n",
       "\n",
       "       native-country_Vietnam  native-country_Hong  native-country_Ireland  \\\n",
       "0                           0                    0                       0   \n",
       "1                           0                    0                       0   \n",
       "4                           0                    0                       0   \n",
       "6                           0                    0                       0   \n",
       "7                           0                    0                       0   \n",
       "...                       ...                  ...                     ...   \n",
       "21106                       0                    0                       0   \n",
       "21108                       0                    0                       0   \n",
       "21111                       0                    0                       0   \n",
       "21112                       0                    0                       0   \n",
       "21113                       0                    0                       0   \n",
       "\n",
       "       native-country_Hungary  native-country_Holand-Netherlands  \n",
       "0                           0                                  0  \n",
       "1                           0                                  0  \n",
       "4                           0                                  0  \n",
       "6                           0                                  0  \n",
       "7                           0                                  0  \n",
       "...                       ...                                ...  \n",
       "21106                       0                                  0  \n",
       "21108                       0                                  0  \n",
       "21111                       0                                  0  \n",
       "21112                       0                                  0  \n",
       "21113                       0                                  0  \n",
       "\n",
       "[13384 rows x 105 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_oob.drop_duplicates().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "546a7893-eeb9-4c6f-89d5-fc64856392e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above we can see that oob and bootstrap do not share the same samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f01caa-3f31-43d0-a7ba-ccfa6855baa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7790e7d-9b5e-43bc-9631-1e0e5954e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I did not need to edit this function from assingment 1/2 as nothing here changed\n",
    "\n",
    "\n",
    "# this is the split point function that we developed in class and used in assignment 1\n",
    "# when we call it in our program we are iterating through a series of values to determine all splitpoints for the feature\n",
    "\n",
    "def split_point_finder(x):\n",
    "  mid_points_in_column = []\n",
    "  x_sorted = sorted(x)\n",
    "\n",
    "  for i in range(0, len(x)-1):\n",
    "    mid_point = ( (x_sorted[i] + x_sorted[i+1]) / 2)\n",
    "    mid_points_in_column.append(mid_point)\n",
    "  return mid_points_in_column\n",
    "\n",
    "\n",
    "\n",
    "# x here is a single column, we create a list to store the midpoints (len column -1 values)\n",
    "# we sort that column, and for every value from 0 to len -1 we take the average of the current column value and the next\n",
    "# we append these midpoints to the list and return that list, giving us a list of midpoints per column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3082584-00bf-4bae-9300-9343dbcaf543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I did not need to edit this function from assingment 1/2 as nothing here changed\n",
    "\n",
    "\n",
    "# this is the left and right node function we developed in class and used in assignment 1\n",
    "# we use this to find the x-y pairs that will go to the left and ride nodes given a certain split point, we test all unique split points with this later\n",
    "\n",
    "def branching_splits(x, y, split_point):\n",
    "  mask = x >= split_point\n",
    "  anti_mask = x < split_point\n",
    "  x_right = x[mask]\n",
    "  x_left = x[anti_mask]\n",
    "  y_right = y[mask]\n",
    "  y_left = y[anti_mask]\n",
    "  return x_right, x_left, y_right, y_left\n",
    "\n",
    "\n",
    "# here we pass in the feature column, the label column and the split point we are using\n",
    "# the mask applies filter values greater or equal to the split point\n",
    "# the anti mask is values less than the split point\n",
    "# we then create true/false or right/left lists of the feature column and the label column with the mask filtering\n",
    "# we return the the true/false or right/left list of the feature column and the corresponding label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04f656d7-17dc-4989-b5c3-bb305dd92501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gini - 1 - summation of proportion of samples in the node that belong to class i, i represents the number of classes ( so for binary it is 0 and 1, 2 classes)\n",
    "def Gini(count_series, samples):\n",
    "    return 1 - sum( ((count / samples) ** 2) for count in count_series)\n",
    "    # here we pass in a series of value counts and the samples in the node\n",
    "    # for each value_count (0 or 1 in my case) in the series ( inreasing the i / summation) \n",
    "    # we calculate the proportion of samples in each class squared and sum them\n",
    "    # then we subtract them from 1 after they have been summed\n",
    "    # This calculates the likelhood of a given classificaiton given the samples, we calculate the likelihood of correctness for classification\n",
    "    # as both 0 and 1 in my dataset. if gini is 0 thats pure, meaning the prediciton would always be correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d1eb374-5594-4252-8f7d-25b217d40db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy - negative summation of proportion of samples in the node that belong to class i * log2 proportion of the samples in the node that belong to class i\n",
    "def Entropy(count_series, samples):\n",
    "    return -sum( ((count / samples) * np.log2((count / samples))) for count in count_series)\n",
    "\n",
    "    # this methodology is similar to gini but with a different equation, we pass in a series of value counts for the class proportions int eh node\n",
    "    # instead of squaring the proportions we do the proportion * log2(proportion), sum them for each class i and then take the inverse of that summation\n",
    "    # the lower the entropy the better- and the larger informationg ain the better :root_entropy - child entropy  = information gain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc89b4dd-8cba-4e93-b3b9-511f780a046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_Entropy(y, y_right, y_left):\n",
    "    # here we need the number of samples in the root and each child node\n",
    "    num_samples_root = len(y)\n",
    "    num_samples_left_child = len(y_left)\n",
    "    num_samples_right_child = len(y_right)\n",
    "\n",
    "    root_entropy = Entropy( y.value_counts(), num_samples_root) # calculate the root node entropy with the class value counts and the num samples\n",
    "\n",
    "    left_child_entropy = Entropy( y_left.value_counts(), num_samples_left_child) # calculate the left child entropy with the class value counts of the left child\n",
    "    # and the num samples in the left child\n",
    "\n",
    "    right_child_entropy = Entropy ( y_right.value_counts(), num_samples_right_child)# calculate the rightchild entropy with the class value counts of the right child\n",
    "    # and the num samples in the right child\n",
    "\n",
    "    weighted_nodes_entropy = (num_samples_left_child / num_samples_root) * left_child_entropy + (num_samples_right_child / num_samples_root) * right_child_entropy\n",
    "    # the weighted entropy is given by taking the proportion of samples the left child entropy represents and adding it \n",
    "    # to the portion of samples the right child entropy represents num_sample_child / root samples = proportion\n",
    "\n",
    "    return root_entropy, weighted_nodes_entropy\n",
    "    # here I do not need to pass the information gain as the function that determines the best split will choose the lowest weighted entropy, which would also have the highest information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9643725b-ed03-41dc-b85e-582453989aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we calculate the node Gini impurity and the weighted leaf/children node impurities\n",
    "\n",
    "def weighted_Gini(y, y_right, y_left):\n",
    "    # value counts for the parent node and the number of samples in the parent and each child\n",
    "    y_counts = y.value_counts()\n",
    "    num_samples_root = len(y)\n",
    "    num_samples_left_child = len(y_left)\n",
    "    num_samples_right_child = len(y_right)\n",
    "\n",
    "    root_gini = Gini( y.value_counts(),  num_samples_root) # root node gini pass in the root node value counts and the number of total samples\n",
    "\n",
    "    left_child_gini = Gini( y_left.value_counts(), num_samples_left_child) # left child value counts and the num samples\n",
    "\n",
    "    right_child_gini = Gini ( y_right.value_counts(), num_samples_right_child)# right child value counts and the num samples\n",
    "\n",
    "    weighted_nodes_gini = (num_samples_left_child / num_samples_root) * left_child_gini + (num_samples_right_child / num_samples_root) * right_child_gini\n",
    "    # to calculate the weighted gini between the child nodes we add the left child gini * leftchild samples / root samples with the right child gini + rightchild samples / root samples\n",
    "    # this weights the two gini scores of the children nodes relative to the number of samples they have\n",
    "\n",
    "    return root_gini, weighted_nodes_gini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa1dd670-ddf0-4210-86ab-03d8c01be9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is pulled from assignment 1 and has a few slight modifications\n",
    "# this functions purpose is to find the best split point and feature at each node of the decision tree\n",
    "# it then returns the feature, split point, root node mse, branching leaf node weighted mse and the dictionary of all errors for the features tested\n",
    "\n",
    "# what we have modified in this code is the ability to randomly select features at each node of the tree, a subset of the total training dataset features\n",
    "# we do this by taking num_random_features_to_choose making it a parameter that can be adjusted in our decision tree creation function\n",
    "# we specify the number of features we want to randomly choose, then before we begin looping for the feautures looking for the best feature / split point\n",
    "# we randomly select from our total features in the dataset columns the parameter number of features to test for the splitting at this node\n",
    "# so if we have a parameter of 5 and 17 feature columns in our dataframe, we randomly choose 5 of those 17 with duplicates not being allowed\n",
    "# from there the function works the same way as assignment 1 where we determine the best split point and feature from those we test to determine the best splitting for this node\n",
    "\n",
    "# we pass in the bootstrap data to this function not the total training dataset\n",
    "def best_branching_random_features(data, label_column_name, num_random_features_to_choose, criterion_equation): \n",
    "\n",
    "  y = data[label_column_name]\n",
    "  possible_features_to_test = data.drop(label_column_name, axis=1) # drop the label column from the dataframe so only features are left\n",
    "\n",
    "  randomized_features_this_node = rng.choice(possible_features_to_test.columns, num_random_features_to_choose, replace = False)\n",
    "  # we use rng.choice to randomly choose (parameter number of features) from (all feature columns that are present in the dataframe) and don't allow duplicates\n",
    "\n",
    "  this_node_data = possible_features_to_test[randomized_features_this_node].copy() # then we create a new dataframe only copying the feature columns selected by our random feature selector above\n",
    "  # we get a smaller dataframe with only the number of features declared in the function parameter\n",
    "\n",
    "  feature_error_dictionary = {}\n",
    "\n",
    "  # In assignment 1 we wouldn't have ran into these errors, but I ran into an error for each of these variables not being initialized\n",
    "  # min error should be set to inf, anythign smaller will replace it\n",
    "  minimum_error = float('inf')\n",
    "\n",
    "  # these 3 can create errors further down our decision tree building if no split points are found to reduce the minimum error, if they arent initialized now and we go to return them\n",
    "  # then we get the errors I pasted in below - if your testing a split with only has 100 samples and for a feature they are all the same value, then no split point exists and these\n",
    "  # values would be left un-initialized given our structure below\n",
    "  root_impurity = float('inf')\n",
    "  best_feature = 'Kelton'\n",
    "  best_split_point_current_feature = 992018683\n",
    "  #UnboundLocalError: cannot access local variable 'best_feature' where it is not associated with a value\n",
    "  #UnboundLocalError: cannot access local variable 'node_mse' where it is not associated with a value\n",
    "  #UnboundLocalError: cannot access local variable 'best_split_point_current_feature' where it is not associated with a value\n",
    "\n",
    "  for feature in this_node_data.columns:\n",
    "    x = data[feature]\n",
    "\n",
    "    split_points = split_point_finder(x)\n",
    "    split_points_unique = np.unique(split_points)\n",
    "\n",
    "    for split_point in split_points_unique:\n",
    "      x_right, x_left, y_right, y_left = branching_splits(x, y, split_point)\n",
    "#####---------------------------NEW --------------------------------------------\n",
    "      # I added a crietion_equation to the function definition as well\n",
    "      # in assignment 3, I use if-elif statemenet blocks for clustering options (linkage or distance formula)\n",
    "      # here I am using a match-case statement block, you could alternate the equation used here throughout the random forest creation\n",
    "      # instead of using mse or mae from a regression model we have implemented a match-case statement to choose between Gini and Entropy\n",
    "      # we use the criterion_equation to designate, this is the only difference in this fucntion\n",
    "      # as with MSE and MAE, the best split points with Gini Impurity and Entropy weighted values are the lowest values so the current logic works\n",
    "      match criterion_equation:\n",
    "        case 'Gini':\n",
    "            unique_errors = weighted_Gini(y,y_right,y_left)\n",
    "            feature_error_dictionary[feature, split_point] = [unique_errors]\n",
    "        case 'Entropy':\n",
    "            unique_errors = weighted_Entropy(y,y_right,y_left)\n",
    "            feature_error_dictionary[feature, split_point] = [unique_errors]\n",
    "        \n",
    "      # for the regression model\n",
    "      # unique_errors = weighted_branch_MSE(y,y_right,y_left)\n",
    "      # feature_error_dictionary[feature, split_point] = [unique_errors]\n",
    "\n",
    "        # recording the best feature and split point based on lowest weighted branch mse from the mse function\n",
    "      if unique_errors[1] < minimum_error:\n",
    "        minimum_error = unique_errors[1]\n",
    "        root_impurity = unique_errors[0]\n",
    "        best_feature = feature\n",
    "        best_split_point_current_feature = split_point\n",
    "\n",
    "  return feature_error_dictionary, root_impurity, minimum_error, best_feature, best_split_point_current_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6085a420-7336-419b-9da0-0d97442cdecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing that the best_branching_random_features function delivers the best split point, feature, and mse of leaves along with root node mse\n",
    "def main(data, label_column_name, num_randomized_features):\n",
    "\n",
    "  dictionary_of_errors_for_node, root_impurity, minimum_error, feature, split_point = best_branching_random_features(data, label_column_name, num_randomized_features, 'Gini')\n",
    "\n",
    "  print(root_impurity)\n",
    "  print(minimum_error)\n",
    "  print(feature)\n",
    "  print(split_point)\n",
    "\n",
    "  return dictionary_of_errors_for_node, root_impurity, minimum_error, feature, split_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8dc8d55e-07d0-4038-9097-d7e365f8c5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.4539056091595938\n",
      "relationship_Own-child\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_column_name = 'income'\n",
    "X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap, all_oob = boot_strap_and_oob(train_data, label_column_name)\n",
    "\n",
    "\n",
    "dictionary_of_errors_for_node, root_mse, branch_mse, feature, split_point = main(bootstrap, label_column_name, num_random_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f56c1584-0ba3-4b8f-94d3-42a67c676a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features chosen in the above split test\n",
    "features = []\n",
    "for feature, split_point in dictionary_of_errors_for_node:\n",
    "  features.append(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39bb3e10-047d-4941-9b7f-a1b034b1e685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['education_10th', 'education_9th', 'education_Assoc-acdm',\n",
       "       'education_HS-grad', 'education_Masters', 'education_Prof-school',\n",
       "       'marital-status_Married-spouse-absent',\n",
       "       'native-country_Dominican-Republic', 'native-country_Ecuador',\n",
       "       'native-country_Jamaica', 'native-country_Japan',\n",
       "       'native-country_Trinadad&Tobago', 'native-country_Vietnam',\n",
       "       'native-country_Yugoslavia', 'occupation_Prof-specialty',\n",
       "       'occupation_Tech-support', 'relationship_Own-child',\n",
       "       'relationship_Wife', 'sex_Male', 'workclass_Federal-gov',\n",
       "       'workclass_Self-emp-inc'], dtype='<U36')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aaa83268-39a6-4208-b310-2227c8f44faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added the criterion_equation to the function definition\n",
    "# changed the prediciton node return from npmean of the node values to returning the mode of the samples in the node for a class label prediction vote\n",
    "\n",
    "\n",
    "# this is my decision tree builder function, which is similar to that of which was built in class but I went with a dictionary instead of a tuple return type\n",
    "# I have set parameters for max depth of the tree, minimum number of samples in a node to try to split it, and a minimum number of samples in the resulting leaves to continue with the splitting\n",
    "\n",
    "\n",
    "# I had to add the criterion_equation hyper parameter to this function definition \n",
    "def dt_builder(bootstrap_current_node, label_column_name, num_randomized_features, minimum_samples_per_leaf, min_samples_per_split, max_depth, criterion_equation , depth = 0):\n",
    "\n",
    "  before_split_sample_size = bootstrap_current_node.shape[0]# get the number of samples in the current parent node\n",
    "\n",
    "\n",
    "  # this is like the max depth checker in the in-class example, but we must also check to make sure that there are enough samples in the parent node to even determine if splitting is worthwhile\n",
    "  if depth >= max_depth or before_split_sample_size < min_samples_per_split: # if depth is >= max depth or there arent enough samples in the parent node then we return a prediction\n",
    "    return {\"prediction_this_node\": bootstrap_current_node[label_column_name].mode()[0]}   #np.mean(bootstrap_current_node[label_column_name])}\n",
    "    # the only difference between the regression model of this function and the classification model is that instead of returning np.mean as a value prediction for the node\n",
    "    # we return the most abundant class label in the prediction node, so a voting-esque system - we take the mode of the samples that are in the node we are returning for our prediction\n",
    "    # and that is our prediciton / vote for the class label for the sample we pass into the prediction defunction that traverses this decision tree\n",
    " \n",
    "    # we have not reached max depth or the minimum number of samples in the parent node, so we call our function to find the best splitting at this node\n",
    "  # we pass thorugh the current node sample, the label, and the number of features to randomly choose\n",
    "  dictionary_of_errors_for_node, root_mse, branch_mse, feature, split_point = best_branching_random_features(bootstrap_current_node, label_column_name, num_randomized_features, criterion_equation)\n",
    "\n",
    "\n",
    "  # this is where I began getting errors for the uninitialized best feature, split and root mse in our branching function\n",
    "  # I have initialized the best feature to my name, if this is returned that means there were no valid split points found in the features randomly selected\n",
    "  # this seems to be due to a small number of samples in the node and the sample feature values being the same, like all having 1.0 floors as an example, no splits found so kelton is returned\n",
    "  # in the case that this non-feature basecase is returned we can no longer split and return this node as a prediction node\n",
    "  if feature == 'Kelton':\n",
    "    # print(feature) # testing\n",
    "    return {\"prediction_this_node\": bootstrap_current_node[label_column_name].mode()[0]} # np.mean(bootstrap_current_node[label_column_name])}\n",
    "    # the only difference between the regression model of this function and the classification model is that instead of returning np.mean as a value prediction for the node\n",
    "    # we return the most abundant class label in the prediction node, so a voting-esque system - we take the mode of the samples that are in the node we are returning for our prediction\n",
    "    # and that is our prediciton / vote for the class label for the sample we pass into the prediction defunction that traverses this decision tree\n",
    "    \n",
    "  # just like branching splits we use vectorized operations on the current node to get the data for the resulting left and right leaf nodes from the split\n",
    "  # I suppose you could store these in the error dictionary from the best_branching_random_features from above\n",
    "  left_node_data = bootstrap_current_node[bootstrap_current_node[feature] < split_point]\n",
    "\n",
    "  right_node_data = bootstrap_current_node[bootstrap_current_node[feature] >= split_point]\n",
    "\n",
    "  # this gets the size of the resulting split leaf nodes, left and right, from the lead node data sets, we get the sizes to check the leaf node sample sizes against the minimum\n",
    "  left_sample_size = left_node_data.shape[0]\n",
    "  right_sample_size = right_node_data.shape[0]\n",
    "\n",
    "  # here we are checking if both the left and right resulting leaf node samples from splitting are greater than or equal to the minimum value parameter we have set\n",
    "  # if either is less than the parameter threshold we do not do the node split and we return the node as a prediction node instead\n",
    "  if left_sample_size < minimum_samples_per_leaf or right_sample_size < minimum_samples_per_leaf:\n",
    "    return {\"prediction_this_node\": bootstrap_current_node[label_column_name].mode()[0]}  #np.mean(bootstrap_current_node[label_column_name])}\n",
    "    # the only difference between the regression model of this function and the classification model is that instead of returning np.mean as a value prediction for the node\n",
    "    # we return the most abundant class label in the prediction node, so a voting-esque system - we take the mode of the samples that are in the node we are returning for our prediction\n",
    "    # and that is our prediciton / vote for the class label for the sample we pass into the prediction defunction that traverses this decision tree\n",
    "    \n",
    " # these are our recrusive calls to this function, for the left nodes and right nodes, each time we increase the depth by 1 so we know if we need to stop the branching due to depth\n",
    " # these calls are what create the tree leaf structure below the root node which is created the first time we call this function\n",
    "  left_leaf_node = dt_builder(left_node_data, label_column_name, num_randomized_features, minimum_samples_per_leaf, min_samples_per_split, max_depth, criterion_equation, depth + 1) #added the criterion_equation to this function call\n",
    "  right_leaf_node = dt_builder(right_node_data, label_column_name, num_randomized_features, minimum_samples_per_leaf, min_samples_per_split, max_depth, criterion_equation, depth + 1)#added the criterion_equation to this function call\n",
    "\n",
    "  # just like our tuple return from the in class version of this code, we return the feature, the split point, the left leaf node and right leaf node, in dictionary form instead of tuples\n",
    "  return { \"feature\": feature, \"split_point\": split_point, \"left_leaf_node\": left_leaf_node, \"right_leaf_node\": right_leaf_node}\n",
    "  # I had dynamic depth tracking in the key of the leaf nodes, but that was making tree navigation more difficult so I opted to remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "590e8e57-1879-4a60-b3ae-420b076e285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I did not need to edit this function from assingment 2 as nothing here changed\n",
    "# we didnt need to change the traversal, only the decision tree builder function to return a class label vote instead of a value prediciton calculated as the label means in the node\n",
    "\n",
    "\n",
    "def predict_traversal(individual_tree, test_data):\n",
    "# in the in class version with tuples and different data format, we can check if isinstance tree,float - which wouldn't work for multiple reasons in this assignment\n",
    "# I have opted for the decision tree to be a dictionary format instead of a tuple, both are hard to read though\n",
    "# instead of checking for a float, because I have set a key for when a node becomes a prediciton, we check for the key \"prediction_this_node\" each time we call this function, and when it finds this key it returns\n",
    "# the prediction value that is associated with that node\n",
    "  if \"prediction_this_node\" in individual_tree:\n",
    "    return individual_tree[\"prediction_this_node\"]\n",
    "\n",
    "  # we need to pull the feature and split point values from each dictionary entry to traverse further down, once we have the feature and the split we can test the value of the feature of the sample datapoint against the split point\n",
    "  # so we use the keys to get the values\n",
    "  current_feature = individual_tree[\"feature\"]\n",
    "  current_split_point = individual_tree[\"split_point\"]\n",
    "\n",
    "\n",
    "  # if the value for this samples feature value is less than the split point we traverse to the left child node\n",
    "  # if the value for this samples feature value is greater than or equal to the split point then we traverse to the right child node\n",
    "  # this traversal will come to an end when we encounter the key indicating a prediciton node\n",
    "  if test_data[current_feature] < current_split_point:\n",
    "    return predict_traversal(individual_tree[\"left_leaf_node\"], test_data) # go to the next left node\n",
    "  else:\n",
    "    return predict_traversal(individual_tree[\"right_leaf_node\"], test_data) # go to the next right node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2a4e1f5-6fe5-444a-8fc5-0a2f55b575d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 'marital-status_Married-civ-spouse',\n",
       " 'split_point': np.float64(0.5),\n",
       " 'left_leaf_node': {'feature': 'age',\n",
       "  'split_point': np.float64(28.5),\n",
       "  'left_leaf_node': {'prediction_this_node': np.int64(0)},\n",
       "  'right_leaf_node': {'feature': 'capital-gain',\n",
       "   'split_point': np.float64(4668.5),\n",
       "   'left_leaf_node': {'feature': 'sex_Male',\n",
       "    'split_point': np.float64(0.5),\n",
       "    'left_leaf_node': {'feature': 'education_HS-grad',\n",
       "     'split_point': np.float64(0.5),\n",
       "     'left_leaf_node': {'feature': 'education-num',\n",
       "      'split_point': np.float64(12.5),\n",
       "      'left_leaf_node': {'feature': 'education_Assoc-voc',\n",
       "       'split_point': np.float64(0.5),\n",
       "       'left_leaf_node': {'prediction_this_node': np.int64(0)},\n",
       "       'right_leaf_node': {'prediction_this_node': np.int64(0)}},\n",
       "      'right_leaf_node': {'prediction_this_node': np.int64(0)}},\n",
       "     'right_leaf_node': {'prediction_this_node': np.int64(0)}},\n",
       "    'right_leaf_node': {'feature': 'capital-gain',\n",
       "     'split_point': np.float64(57.0),\n",
       "     'left_leaf_node': {'feature': 'education_Prof-school',\n",
       "      'split_point': np.float64(0.5),\n",
       "      'left_leaf_node': {'feature': 'hours-per-week',\n",
       "       'split_point': np.float64(43.5),\n",
       "       'left_leaf_node': {'prediction_this_node': np.int64(0)},\n",
       "       'right_leaf_node': {'prediction_this_node': np.int64(0)}},\n",
       "      'right_leaf_node': {'prediction_this_node': np.int64(1)}},\n",
       "     'right_leaf_node': {'prediction_this_node': np.int64(0)}}},\n",
       "   'right_leaf_node': {'feature': 'occupation_Farming-fishing',\n",
       "    'split_point': np.float64(0.5),\n",
       "    'left_leaf_node': {'feature': 'workclass_Federal-gov',\n",
       "     'split_point': np.float64(0.5),\n",
       "     'left_leaf_node': {'prediction_this_node': np.int64(1)},\n",
       "     'right_leaf_node': {'prediction_this_node': np.int64(1)}},\n",
       "    'right_leaf_node': {'prediction_this_node': np.int64(1)}}}},\n",
       " 'right_leaf_node': {'feature': 'education-num',\n",
       "  'split_point': np.float64(11.5),\n",
       "  'left_leaf_node': {'feature': 'occupation_Other-service',\n",
       "   'split_point': np.float64(0.5),\n",
       "   'left_leaf_node': {'feature': 'age',\n",
       "    'split_point': np.float64(33.5),\n",
       "    'left_leaf_node': {'feature': 'education-num',\n",
       "     'split_point': np.float64(7.5),\n",
       "     'left_leaf_node': {'feature': 'education_7th-8th',\n",
       "      'split_point': np.float64(0.5),\n",
       "      'left_leaf_node': {'prediction_this_node': np.int64(0)},\n",
       "      'right_leaf_node': {'prediction_this_node': np.int64(0)}},\n",
       "     'right_leaf_node': {'feature': 'workclass_Federal-gov',\n",
       "      'split_point': np.float64(0.5),\n",
       "      'left_leaf_node': {'feature': 'native-country_Cuba',\n",
       "       'split_point': np.float64(0.5),\n",
       "       'left_leaf_node': {'prediction_this_node': np.int64(0)},\n",
       "       'right_leaf_node': {'prediction_this_node': np.int64(1)}},\n",
       "      'right_leaf_node': {'prediction_this_node': np.int64(1)}}},\n",
       "    'right_leaf_node': {'feature': 'workclass_Self-emp-not-inc',\n",
       "     'split_point': np.float64(0.5),\n",
       "     'left_leaf_node': {'feature': 'education_9th',\n",
       "      'split_point': np.float64(0.5),\n",
       "      'left_leaf_node': {'feature': 'education_10th',\n",
       "       'split_point': np.float64(0.5),\n",
       "       'left_leaf_node': {'prediction_this_node': np.int64(1)},\n",
       "       'right_leaf_node': {'prediction_this_node': np.int64(0)}},\n",
       "      'right_leaf_node': {'prediction_this_node': np.int64(0)}},\n",
       "     'right_leaf_node': {'feature': 'education_10th',\n",
       "      'split_point': np.float64(0.5),\n",
       "      'left_leaf_node': {'feature': 'age',\n",
       "       'split_point': np.float64(61.5),\n",
       "       'left_leaf_node': {'prediction_this_node': np.int64(1)},\n",
       "       'right_leaf_node': {'prediction_this_node': np.int64(0)}},\n",
       "      'right_leaf_node': {'prediction_this_node': np.int64(0)}}}},\n",
       "   'right_leaf_node': {'feature': 'age',\n",
       "    'split_point': np.float64(33.5),\n",
       "    'left_leaf_node': {'prediction_this_node': np.int64(0)},\n",
       "    'right_leaf_node': {'feature': 'capital-gain',\n",
       "     'split_point': np.float64(6155.5),\n",
       "     'left_leaf_node': {'feature': 'fnlwgt',\n",
       "      'split_point': np.float64(99528.0),\n",
       "      'left_leaf_node': {'feature': 'native-country_United-States',\n",
       "       'split_point': np.float64(0.5),\n",
       "       'left_leaf_node': {'prediction_this_node': np.int64(0)},\n",
       "       'right_leaf_node': {'prediction_this_node': np.int64(0)}},\n",
       "      'right_leaf_node': {'feature': 'age',\n",
       "       'split_point': np.float64(34.5),\n",
       "       'left_leaf_node': {'prediction_this_node': np.int64(1)},\n",
       "       'right_leaf_node': {'prediction_this_node': np.int64(0)}}},\n",
       "     'right_leaf_node': {'prediction_this_node': np.int64(1)}}}},\n",
       "  'right_leaf_node': {'feature': 'occupation_Exec-managerial',\n",
       "   'split_point': np.float64(0.5),\n",
       "   'left_leaf_node': {'feature': 'education-num',\n",
       "    'split_point': np.float64(13.5),\n",
       "    'left_leaf_node': {'feature': 'native-country_South',\n",
       "     'split_point': np.float64(0.5),\n",
       "     'left_leaf_node': {'feature': 'occupation_Sales',\n",
       "      'split_point': np.float64(0.5),\n",
       "      'left_leaf_node': {'feature': 'occupation_Prof-specialty',\n",
       "       'split_point': np.float64(0.5),\n",
       "       'left_leaf_node': {'prediction_this_node': np.int64(1)},\n",
       "       'right_leaf_node': {'prediction_this_node': np.int64(1)}},\n",
       "      'right_leaf_node': {'prediction_this_node': np.int64(1)}},\n",
       "     'right_leaf_node': {'prediction_this_node': np.int64(0)}},\n",
       "    'right_leaf_node': {'feature': 'occupation_Adm-clerical',\n",
       "     'split_point': np.float64(0.5),\n",
       "     'left_leaf_node': {'feature': 'education-num',\n",
       "      'split_point': np.float64(14.5),\n",
       "      'left_leaf_node': {'prediction_this_node': np.int64(1)},\n",
       "      'right_leaf_node': {'feature': 'native-country_South',\n",
       "       'split_point': np.float64(0.5),\n",
       "       'left_leaf_node': {'prediction_this_node': np.int64(1)},\n",
       "       'right_leaf_node': {'prediction_this_node': np.int64(1)}}},\n",
       "     'right_leaf_node': {'prediction_this_node': np.int64(1)}}},\n",
       "   'right_leaf_node': {'feature': 'capital-gain',\n",
       "    'split_point': np.float64(5095.5),\n",
       "    'left_leaf_node': {'feature': 'workclass_Federal-gov',\n",
       "     'split_point': np.float64(0.5),\n",
       "     'left_leaf_node': {'feature': 'age',\n",
       "      'split_point': np.float64(54.5),\n",
       "      'left_leaf_node': {'prediction_this_node': np.int64(1)},\n",
       "      'right_leaf_node': {'prediction_this_node': np.int64(1)}},\n",
       "     'right_leaf_node': {'feature': 'education_Masters',\n",
       "      'split_point': np.float64(0.5),\n",
       "      'left_leaf_node': {'prediction_this_node': np.int64(1)},\n",
       "      'right_leaf_node': {'prediction_this_node': np.int64(1)}}},\n",
       "    'right_leaf_node': {'prediction_this_node': np.int64(1)}}}}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a single test decision tree, min samples, min samples to even try to split is at least 2x the minimum samples per leaf\n",
    "# I was trying to experiment with setting the min samples to consider splitting higher than 2x the min samples per leaf\n",
    "# max depth of 10, https://www.geeksforgeeks.org/how-to-choose-ideal-decision-tree-depth-without-overfitting/\n",
    "# in the link they are using a classifier model, so this may be irrelevant to a regression model\n",
    "# but they test depths from 1-15 and their accuraccy seems to almost peak around a max depth of 7\n",
    "# I have been testing between 3-12 and I seem to be getting the best results around 8-12 given the parameter of 4 randomly chosen features I have been using,\n",
    "\n",
    "minimum_samples_per_leaf = 5\n",
    "min_samples_per_split = (minimum_samples_per_leaf * 2) + 1\n",
    "max_depth = 7\n",
    "\n",
    "X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap_current_node, all_oob = boot_strap_and_oob(train_data, label_column_name)\n",
    "individual_tree_dict = dt_builder(bootstrap_current_node, label_column_name, num_random_features, minimum_samples_per_leaf, min_samples_per_split, max_depth,criterion_equation = 'Gini', depth = 0)\n",
    "individual_tree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f7bff36-7e0f-4e20-8050-665a3f2add55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the only edit to this function was adding in the random forest hyper parameters:\n",
    "# criterion_equation, max_depth, minimum_samples_per_leaf, min_samples_per_split \n",
    "\n",
    "# These were already implemented in my decision tree function but I was not passing them as a parameter into my random forect classifier\n",
    "# I was simply declaring them inside of the classifier function, but now I am passing them through the classiifier function definiton parameters to the decisiont tree builder function\n",
    "\n",
    "\n",
    "\n",
    "# so with the functionality of our decision tree builder and prediction recursive functions established, the random forest regressor and the aggregate prediciton functions are not too difficult\n",
    "# we just need to create loops to build enough trees to become a forest of X size, and then traverse all of them to make predictions with the forest structure\n",
    "# here we need to pass in all of the parameters that we need, the training data, label, number of tree to build, the num of random features and the bootstramp sample size which should match out training sample size\n",
    "\n",
    "def random_forest_classifier_from_scratch(data, label_column_name, number_of_trees, num_randomized_features, criterion_equation, max_depth, minimum_samples_per_leaf, min_samples_per_split ):\n",
    "\n",
    "  forest_of_trees_dict = {}\n",
    "\n",
    "  # these 3 variables are the ones that we change to try and tune our trees which resulting in tuning the forest\n",
    "  # I have been fiddling with these to get lower MSE's in our testing results\n",
    "  # 8500 split values rounded up are 4250, 2125, 1063, 532, 266, 133, 67, 34, 17, 9, 5, 3, 2\n",
    "  # at 13 splits we are getting leafs with very few samples\n",
    "  # I was getting some of my best results at min samples 9, max depth 10 if I recall\n",
    "  minimum_samples_per_leaf =  minimum_samples_per_leaf\n",
    "  min_samples_per_split = min_samples_per_split # this is me rounding up when determining how many samples in the current node are needed to even try to split before testing leaf # samples\n",
    "  max_depth = max_depth\n",
    "\n",
    "  each_entry_oob =[]\n",
    "\n",
    "  #build all the trees paramaterized\n",
    "  for i in range(number_of_trees):\n",
    "\n",
    "    # each tree gets its own bootstrap, everytime we call dt_builder we need a new bootstrap\n",
    "    #dt_builder builds trees with randomized features at each node of the tree\n",
    "    # then we store all of the OOB df indices to a list, you could store the whole dataframe, but when I access them later I only need the index values, so I am going to take only those now\n",
    "    # you can use list(df indices) or the method that I used as .tolist() - I do remember seeing one comment on a website stating something about how list(df indices) might be safer or more reliable for some data structures? something to do with numpy I believe\n",
    "    # we then store each tree in a  forest dictionary entry, the key is the tree number and the value is a tuple with value[0] = dictionary that is the tree itself, and value[1] is the array of indices of the oob values for the bootstrap sample used in building the tree\n",
    "    X_bootstrap, y_bootstrap, X_oob, y_oob, bootstrap_current_node, all_oob = boot_strap_and_oob(data, label_column_name)\n",
    "    individual_tree_dict = dt_builder(bootstrap_current_node, label_column_name, num_randomized_features, minimum_samples_per_leaf, min_samples_per_split, max_depth, criterion_equation, depth = 0)\n",
    "    each_entry_oob_indices = all_oob.index.values.tolist()\n",
    "    forest_of_trees_dict[i] = individual_tree_dict , each_entry_oob_indices\n",
    "\n",
    "# then we return the forest dictionary\n",
    "  return forest_of_trees_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d665a33-2d87-4f1a-9479-53b8cd297265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added the hyperparameters tot he main function and the random forest classifier function\n",
    "\n",
    "# testing the forest\n",
    "# determining the bootstrap sample size from the data passed into main, whereas num trees and num randomized features are currently being passed into main\n",
    "# its likely better to have them set as variables within the function that calls the forest creator\n",
    "def main3(data, label_column_name, number_of_trees, num_randomized_features, criterion_equation, max_depth, minimum_samples_per_leaf, min_samples_per_split ):\n",
    "    forest_dict_trees = random_forest_classifier_from_scratch(data, label_column_name, number_of_trees, num_randomized_features, criterion_equation, max_depth, minimum_samples_per_leaf, min_samples_per_split)\n",
    "    return forest_dict_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f98a55d0-3efd-43aa-bb62-023297edf905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling main to create the forest with num trees, the number of randomized features and the other hyper params\n",
    "\n",
    "\n",
    "#num_randomized_features = num_random_features # we declared this above, you can change the value to anything though, currently ceil(sqrt(features)*2)\n",
    "num_randomized_features = 16 # lets try something in between sqrt and sqrt * 2\n",
    "number_of_trees =  111\n",
    "criterion_equation = 'Gini' # 'Gini' or 'Entropy' are only supported\n",
    "max_depth = 7\n",
    "minimum_samples_per_leaf = 15\n",
    "min_samples_per_split = 31\n",
    "\n",
    "forest_dict_trees = main3(train_data, label_column_name, number_of_trees, num_randomized_features, criterion_equation, max_depth, minimum_samples_per_leaf, min_samples_per_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f56eb06-3a01-4677-bead-9a22b34b27fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function needed to be edited for the regression to classifier change as the predictions have significantly changed\n",
    "# instead of taking an aggregate of all the individual decision tree predictions and taking the average of it to the return a mean random forest prediciton\n",
    "# we instead declare a list to store the binary label class votes from each decision tree, so our decision trees now return a prediction for the samples' label feature \n",
    "# a binary classification predicition as we only have two categories in our label in this dataset\n",
    "# so once we traverse all of the trees in the randomforest and get their classificaiton prediciton, we do a majority vote for what the random forest will return\n",
    "# to do this we turn the list that was storing all of the decision tree individual votes into a pandas series and we return its mode, \n",
    "# which will return the classification prediction with the largest value_count  / the most frequent vote\n",
    "# we traverse \n",
    "\n",
    "def aggregate_prediction(forest_dict_trees, test_data):\n",
    "  votes = [] # list to store each tree prediction\n",
    "\n",
    "  # here we iterate through the tree,oob value pairs in each of the decision trees in our forest dicitonary\n",
    "  # tree index: tree-dict, oob array in the items list of our forest dictionary\n",
    "  # for each entry/item/key:value pair we grab the tree in the value and we traverse it given our test_data sample that we pass into the aggregate_prediction function\n",
    "  # so we call the individual tree prediction function for each each tree and use the same sample data for each tree as we want an aggregate prediction acrros all trees in the forest\n",
    "  for tree_index, (individual_tree, oob_indices) in forest_dict_trees.items():\n",
    "    vote = predict_traversal(individual_tree, test_data) # traverse the tree and get a prediction\n",
    "    votes.append(vote) # we add the prediction to our list of predicitons \n",
    "\n",
    "  votes_pandas = pd.Series(votes) # we divide the sum of the predictions by the number of trees we have in our forest\n",
    "  return votes_pandas.mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6f7749f-7118-4551-8b8d-fb153ff3c3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21094    1\n",
       "21095    0\n",
       "21096    0\n",
       "21097    0\n",
       "21098    0\n",
       "21099    1\n",
       "21100    0\n",
       "21101    1\n",
       "21102    0\n",
       "21103    0\n",
       "21104    0\n",
       "21105    0\n",
       "21106    0\n",
       "21107    1\n",
       "21108    0\n",
       "21109    1\n",
       "21110    1\n",
       "21111    0\n",
       "21112    0\n",
       "21113    0\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['income'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5a515e9-e6f9-4616-a9b3-7e660b603af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_prediction(forest_dict_trees, train_data.iloc[21092])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "83d6e007-7a62-488f-8cf4-8fc63a4b6d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_prediction(forest_dict_trees, train_data.iloc[21095])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec881f42-6f67-44fe-9663-9281bb1f8176",
   "metadata": {},
   "source": [
    "# SKLEARN on my datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "292ddc73-007f-4538-9ae0-9cc095643efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here is my sklearn random forest classifier with the exact same dataset I built for my from_scratch function\n",
    "# we need to declare x_train, y_train and x_test and y_test\n",
    "X_train_mine = train_data.drop(label_column_name, axis=1)\n",
    "y_train_mine = train_data[label_column_name]\n",
    "\n",
    "X_test_mine = test_data.drop(label_column_name, axis=1)\n",
    "y_test_mine = test_data[label_column_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c0725e3-a0c7-46a2-832b-7758d6e4bd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21114, 104)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "118032ff-d51b-4d30-9315-bbf80ddc4c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9047, 104)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f15c739b-2ccf-4a79-b744-a189c77c6f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=75, n_jobs=-1, random_state=110)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=75, n_jobs=-1, random_state=110)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=75, n_jobs=-1, random_state=110)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we build the model in sklearn \n",
    "sklearn_rf_model_mine = RandomForestClassifier(n_estimators=75, criterion='gini', max_features='sqrt', bootstrap=True, n_jobs=-1, random_state=110)\n",
    "sklearn_rf_model_mine.fit(X_train_mine,y_train_mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0c7fed4-6970-4a42-b9f7-2efd8c4112d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions_mine = sklearn_rf_model_mine.predict(X_test_mine) # make predicitions for all of the x_test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d1b7b7ba-0e62-4dfa-8f07-16717f2d594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6253,  542],\n",
       "       [ 813, 1439]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I implement a confusion matrix from scratch for my own implementation of the classifier\n",
    "# but here I use confusion matrix from sklearn\n",
    "# we declear the confusion matrix for this random forest classifier implementation and we get an np array return\n",
    "cm_mine = confusion_matrix(y_test_mine,y_predictions_mine)\n",
    "cm_mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da813f4f-e26f-4e8b-aa2e-badee06ae769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we flatten this mulitdimentional array into its 4 componenets\n",
    "# we use these in a comparision further down\n",
    "tn_sklearn, fp_sklearn, fn_sklearn, tp_sklearn = cm_mine.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec58202-2277-4a3e-8ff2-8e5b74870c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace6e1e3-b9ec-4492-978a-161f743d342a",
   "metadata": {},
   "source": [
    "# All SKLEARN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0fde395a-19f1-4711-9c38-cbf64eac3649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "# I wanted to test my implementation against an SKlearn implementation that used an sklearn encoded dataset\n",
    "# so I leave my binary label encoding from earlier, where we created sklean_data\n",
    "# then we create a oneHotEncoder without sparse output so that we get an np array and the parameter to create concatenated column names\n",
    "encoder = OneHotEncoder(sparse_output=False, feature_name_combiner=\"concat\") \n",
    "encoded_cols = encoder.fit_transform(sklearn_data[cols_categorical]) # here we use the encoder to transform all of the categorical columns, income has been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45269eef-31df-4c00-843c-309995ccc6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]], shape=(30161, 98))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9f7ce4fa-8397-4ed2-aad8-c55a9a8f9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = encoder.get_feature_names_out(cols_categorical) # here we extract the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f2f14add-de1e-4140-ab8a-95155be7ab15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['workclass_Federal-gov', 'workclass_Local-gov',\n",
       "       'workclass_Private', 'workclass_Self-emp-inc',\n",
       "       'workclass_Self-emp-not-inc', 'workclass_State-gov',\n",
       "       'workclass_Without-pay', 'education_10th', 'education_11th',\n",
       "       'education_12th', 'education_1st-4th', 'education_5th-6th',\n",
       "       'education_7th-8th', 'education_9th', 'education_Assoc-acdm',\n",
       "       'education_Assoc-voc', 'education_Bachelors',\n",
       "       'education_Doctorate', 'education_HS-grad', 'education_Masters',\n",
       "       'education_Preschool', 'education_Prof-school',\n",
       "       'education_Some-college', 'marital-status_Divorced',\n",
       "       'marital-status_Married-AF-spouse',\n",
       "       'marital-status_Married-civ-spouse',\n",
       "       'marital-status_Married-spouse-absent',\n",
       "       'marital-status_Never-married', 'marital-status_Separated',\n",
       "       'marital-status_Widowed', 'occupation_Adm-clerical',\n",
       "       'occupation_Armed-Forces', 'occupation_Craft-repair',\n",
       "       'occupation_Exec-managerial', 'occupation_Farming-fishing',\n",
       "       'occupation_Handlers-cleaners', 'occupation_Machine-op-inspct',\n",
       "       'occupation_Other-service', 'occupation_Priv-house-serv',\n",
       "       'occupation_Prof-specialty', 'occupation_Protective-serv',\n",
       "       'occupation_Sales', 'occupation_Tech-support',\n",
       "       'occupation_Transport-moving', 'relationship_Husband',\n",
       "       'relationship_Not-in-family', 'relationship_Other-relative',\n",
       "       'relationship_Own-child', 'relationship_Unmarried',\n",
       "       'relationship_Wife', 'race_Amer-Indian-Eskimo',\n",
       "       'race_Asian-Pac-Islander', 'race_Black', 'race_Other',\n",
       "       'race_White', 'sex_Female', 'sex_Male', 'native-country_Cambodia',\n",
       "       'native-country_Canada', 'native-country_China',\n",
       "       'native-country_Columbia', 'native-country_Cuba',\n",
       "       'native-country_Dominican-Republic', 'native-country_Ecuador',\n",
       "       'native-country_El-Salvador', 'native-country_England',\n",
       "       'native-country_France', 'native-country_Germany',\n",
       "       'native-country_Greece', 'native-country_Guatemala',\n",
       "       'native-country_Haiti', 'native-country_Holand-Netherlands',\n",
       "       'native-country_Honduras', 'native-country_Hong',\n",
       "       'native-country_Hungary', 'native-country_India',\n",
       "       'native-country_Iran', 'native-country_Ireland',\n",
       "       'native-country_Italy', 'native-country_Jamaica',\n",
       "       'native-country_Japan', 'native-country_Laos',\n",
       "       'native-country_Mexico', 'native-country_Nicaragua',\n",
       "       'native-country_Outlying-US(Guam-USVI-etc)', 'native-country_Peru',\n",
       "       'native-country_Philippines', 'native-country_Poland',\n",
       "       'native-country_Portugal', 'native-country_Puerto-Rico',\n",
       "       'native-country_Scotland', 'native-country_South',\n",
       "       'native-country_Taiwan', 'native-country_Thailand',\n",
       "       'native-country_Trinadad&Tobago', 'native-country_United-States',\n",
       "       'native-country_Vietnam', 'native-country_Yugoslavia'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "891b6887-bd15-4e74-9ef2-2c59bc19ebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>workclass_Without-pay</th>\n",
       "      <th>education_10th</th>\n",
       "      <th>education_11th</th>\n",
       "      <th>education_12th</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30161 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass_Federal-gov  workclass_Local-gov  workclass_Private  \\\n",
       "0                        0.0                  0.0                0.0   \n",
       "1                        0.0                  0.0                1.0   \n",
       "2                        0.0                  0.0                1.0   \n",
       "3                        0.0                  0.0                1.0   \n",
       "4                        0.0                  0.0                1.0   \n",
       "...                      ...                  ...                ...   \n",
       "32555                    0.0                  0.0                1.0   \n",
       "32556                    0.0                  0.0                1.0   \n",
       "32557                    0.0                  0.0                1.0   \n",
       "32558                    0.0                  0.0                1.0   \n",
       "32559                    0.0                  0.0                0.0   \n",
       "\n",
       "       workclass_Self-emp-inc  workclass_Self-emp-not-inc  \\\n",
       "0                         0.0                         1.0   \n",
       "1                         0.0                         0.0   \n",
       "2                         0.0                         0.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "...                       ...                         ...   \n",
       "32555                     0.0                         0.0   \n",
       "32556                     0.0                         0.0   \n",
       "32557                     0.0                         0.0   \n",
       "32558                     0.0                         0.0   \n",
       "32559                     1.0                         0.0   \n",
       "\n",
       "       workclass_State-gov  workclass_Without-pay  education_10th  \\\n",
       "0                      0.0                    0.0             0.0   \n",
       "1                      0.0                    0.0             0.0   \n",
       "2                      0.0                    0.0             0.0   \n",
       "3                      0.0                    0.0             0.0   \n",
       "4                      0.0                    0.0             0.0   \n",
       "...                    ...                    ...             ...   \n",
       "32555                  0.0                    0.0             0.0   \n",
       "32556                  0.0                    0.0             0.0   \n",
       "32557                  0.0                    0.0             0.0   \n",
       "32558                  0.0                    0.0             0.0   \n",
       "32559                  0.0                    0.0             0.0   \n",
       "\n",
       "       education_11th  education_12th  ...  native-country_Portugal  \\\n",
       "0                 0.0             0.0  ...                      0.0   \n",
       "1                 0.0             0.0  ...                      0.0   \n",
       "2                 1.0             0.0  ...                      0.0   \n",
       "3                 0.0             0.0  ...                      0.0   \n",
       "4                 0.0             0.0  ...                      0.0   \n",
       "...               ...             ...  ...                      ...   \n",
       "32555             0.0             0.0  ...                      0.0   \n",
       "32556             0.0             0.0  ...                      0.0   \n",
       "32557             0.0             0.0  ...                      0.0   \n",
       "32558             0.0             0.0  ...                      0.0   \n",
       "32559             0.0             0.0  ...                      0.0   \n",
       "\n",
       "       native-country_Puerto-Rico  native-country_Scotland  \\\n",
       "0                             0.0                      0.0   \n",
       "1                             0.0                      0.0   \n",
       "2                             0.0                      0.0   \n",
       "3                             0.0                      0.0   \n",
       "4                             0.0                      0.0   \n",
       "...                           ...                      ...   \n",
       "32555                         0.0                      0.0   \n",
       "32556                         0.0                      0.0   \n",
       "32557                         0.0                      0.0   \n",
       "32558                         0.0                      0.0   \n",
       "32559                         0.0                      0.0   \n",
       "\n",
       "       native-country_South  native-country_Taiwan  native-country_Thailand  \\\n",
       "0                       0.0                    0.0                      0.0   \n",
       "1                       0.0                    0.0                      0.0   \n",
       "2                       0.0                    0.0                      0.0   \n",
       "3                       0.0                    0.0                      0.0   \n",
       "4                       0.0                    0.0                      0.0   \n",
       "...                     ...                    ...                      ...   \n",
       "32555                   0.0                    0.0                      0.0   \n",
       "32556                   0.0                    0.0                      0.0   \n",
       "32557                   0.0                    0.0                      0.0   \n",
       "32558                   0.0                    0.0                      0.0   \n",
       "32559                   0.0                    0.0                      0.0   \n",
       "\n",
       "       native-country_Trinadad&Tobago  native-country_United-States  \\\n",
       "0                                 0.0                           1.0   \n",
       "1                                 0.0                           1.0   \n",
       "2                                 0.0                           1.0   \n",
       "3                                 0.0                           0.0   \n",
       "4                                 0.0                           1.0   \n",
       "...                               ...                           ...   \n",
       "32555                             0.0                           1.0   \n",
       "32556                             0.0                           1.0   \n",
       "32557                             0.0                           1.0   \n",
       "32558                             0.0                           1.0   \n",
       "32559                             0.0                           1.0   \n",
       "\n",
       "       native-country_Vietnam  native-country_Yugoslavia  \n",
       "0                         0.0                        0.0  \n",
       "1                         0.0                        0.0  \n",
       "2                         0.0                        0.0  \n",
       "3                         0.0                        0.0  \n",
       "4                         0.0                        0.0  \n",
       "...                       ...                        ...  \n",
       "32555                     0.0                        0.0  \n",
       "32556                     0.0                        0.0  \n",
       "32557                     0.0                        0.0  \n",
       "32558                     0.0                        0.0  \n",
       "32559                     0.0                        0.0  \n",
       "\n",
       "[30161 rows x 98 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_cols_add = pd.DataFrame(encoded_cols, columns = feature_names, index = sklearn_data.index)\n",
    "encoded_cols_add\n",
    "# now we create a dataframe with our new columns and the extracted feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2695960b-b12c-4eb6-84a3-2e4fe4f8d849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>284582</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>27</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>40</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>58</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>22</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>52</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30161 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0       50   83311             13             0             0              13   \n",
       "1       38  215646              9             0             0              40   \n",
       "2       53  234721              7             0             0              40   \n",
       "3       28  338409             13             0             0              40   \n",
       "4       37  284582             14             0             0              40   \n",
       "...    ...     ...            ...           ...           ...             ...   \n",
       "32555   27  257302             12             0             0              38   \n",
       "32556   40  154374              9             0             0              40   \n",
       "32557   58  151910              9             0             0              40   \n",
       "32558   22  201490              9             0             0              20   \n",
       "32559   52  287927              9         15024             0              40   \n",
       "\n",
       "       income  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "32555       0  \n",
       "32556       1  \n",
       "32557       0  \n",
       "32558       0  \n",
       "32559       1  \n",
       "\n",
       "[30161 rows x 7 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped = sklearn_data.drop(cols_categorical, axis =1)\n",
    "dropped # then we drop all of the categorical columns like we did before\n",
    "# drop them from axis 1 as they are columns in the dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f52ea299-fd66-443f-8cb5-6942b19b7de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>284582</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>27</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>40</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>58</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>22</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>52</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30161 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0       50   83311             13             0             0              13   \n",
       "1       38  215646              9             0             0              40   \n",
       "2       53  234721              7             0             0              40   \n",
       "3       28  338409             13             0             0              40   \n",
       "4       37  284582             14             0             0              40   \n",
       "...    ...     ...            ...           ...           ...             ...   \n",
       "32555   27  257302             12             0             0              38   \n",
       "32556   40  154374              9             0             0              40   \n",
       "32557   58  151910              9             0             0              40   \n",
       "32558   22  201490              9             0             0              20   \n",
       "32559   52  287927              9         15024             0              40   \n",
       "\n",
       "       income  workclass_Federal-gov  workclass_Local-gov  workclass_Private  \\\n",
       "0           0                    0.0                  0.0                0.0   \n",
       "1           0                    0.0                  0.0                1.0   \n",
       "2           0                    0.0                  0.0                1.0   \n",
       "3           0                    0.0                  0.0                1.0   \n",
       "4           0                    0.0                  0.0                1.0   \n",
       "...       ...                    ...                  ...                ...   \n",
       "32555       0                    0.0                  0.0                1.0   \n",
       "32556       1                    0.0                  0.0                1.0   \n",
       "32557       0                    0.0                  0.0                1.0   \n",
       "32558       0                    0.0                  0.0                1.0   \n",
       "32559       1                    0.0                  0.0                0.0   \n",
       "\n",
       "       ...  native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "0      ...                      0.0                         0.0   \n",
       "1      ...                      0.0                         0.0   \n",
       "2      ...                      0.0                         0.0   \n",
       "3      ...                      0.0                         0.0   \n",
       "4      ...                      0.0                         0.0   \n",
       "...    ...                      ...                         ...   \n",
       "32555  ...                      0.0                         0.0   \n",
       "32556  ...                      0.0                         0.0   \n",
       "32557  ...                      0.0                         0.0   \n",
       "32558  ...                      0.0                         0.0   \n",
       "32559  ...                      0.0                         0.0   \n",
       "\n",
       "       native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "0                          0.0                   0.0                    0.0   \n",
       "1                          0.0                   0.0                    0.0   \n",
       "2                          0.0                   0.0                    0.0   \n",
       "3                          0.0                   0.0                    0.0   \n",
       "4                          0.0                   0.0                    0.0   \n",
       "...                        ...                   ...                    ...   \n",
       "32555                      0.0                   0.0                    0.0   \n",
       "32556                      0.0                   0.0                    0.0   \n",
       "32557                      0.0                   0.0                    0.0   \n",
       "32558                      0.0                   0.0                    0.0   \n",
       "32559                      0.0                   0.0                    0.0   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "0                          0.0                             0.0   \n",
       "1                          0.0                             0.0   \n",
       "2                          0.0                             0.0   \n",
       "3                          0.0                             0.0   \n",
       "4                          0.0                             0.0   \n",
       "...                        ...                             ...   \n",
       "32555                      0.0                             0.0   \n",
       "32556                      0.0                             0.0   \n",
       "32557                      0.0                             0.0   \n",
       "32558                      0.0                             0.0   \n",
       "32559                      0.0                             0.0   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "0                               1.0                     0.0   \n",
       "1                               1.0                     0.0   \n",
       "2                               1.0                     0.0   \n",
       "3                               0.0                     0.0   \n",
       "4                               1.0                     0.0   \n",
       "...                             ...                     ...   \n",
       "32555                           1.0                     0.0   \n",
       "32556                           1.0                     0.0   \n",
       "32557                           1.0                     0.0   \n",
       "32558                           1.0                     0.0   \n",
       "32559                           1.0                     0.0   \n",
       "\n",
       "       native-country_Yugoslavia  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "...                          ...  \n",
       "32555                        0.0  \n",
       "32556                        0.0  \n",
       "32557                        0.0  \n",
       "32558                        0.0  \n",
       "32559                        0.0  \n",
       "\n",
       "[30161 rows x 105 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_data_encoded = pd.concat([dropped, encoded_cols_add], axis = 1)\n",
    "sklearn_data_encoded #now we concatenant the oneHot encoded columns with what is left from our un-encoded starting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f8251a89-4ca1-4419-bc33-0647f7e798b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so this above was to validate my encoding at the begenning of this notebook and to test if their implementation made \n",
    "# a meaninful difference with the sklearn implementation of the classifier over mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4a77cce4-bc7b-4924-bf96-82866c8e87c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sklearn_data_encoded.drop(label_column_name, axis=1) # declare X and y for train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd481881-d25f-4e73-9c6d-7884069773e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sklearn_data_encoded[label_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "917b4789-b7cb-415e-819a-0fc8542c86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split (X, y, test_size = 0.3, random_state = 110, stratify= y)\n",
    "# my implementation of train_test_split should produce similar results, this output will also be stratified and perserve 30% of the data for testing\n",
    "# I believe they round up and I round down with int in my implementation, if I recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ef6fc25e-1018-4dcd-b69c-da1f1daa8309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21112, 104)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "af7822ad-2f49-4909-8ae5-b6518e94d5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9049, 104)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "743379ff-d27b-4b6d-b040-5060be796466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=75, n_jobs=-1,\n",
       "                       random_state=110)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=75, n_jobs=-1,\n",
       "                       random_state=110)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=75, n_jobs=-1,\n",
       "                       random_state=110)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)[source]\n",
    "# above is all of the parameters for sklearn RF Classifier\n",
    "\n",
    "#this time I am running the model with entropy, whereas the one built on my dataset was using gini impurity\n",
    "\n",
    "# sklearn_rf_model = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=10, min_samples_leaf=5, max_features='sqrt', bootstrap=True, oob_score=False, n_jobs=-1, random_state=110)\n",
    "sklearn_rf_model = RandomForestClassifier(n_estimators=75, criterion='entropy', max_features='sqrt', bootstrap=True, n_jobs=-1, random_state=110)\n",
    "\n",
    "sklearn_rf_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "715b25d5-1fd5-4199-bab0-fc7b75910e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = sklearn_rf_model.predict(X_test) # make predicitons on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fb9e5bdd-caf9-4851-9193-b28418d25c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6265,  531],\n",
       "       [ 831, 1422]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_all_sklearn = confusion_matrix(y_test,y_predictions)\n",
    "cm_all_sklearn # create a confusion matrix  with the prediciton results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2c4ecce0-4927-41b4-8736-f439a2ba4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_all_sklearn_entropy, fp_all_sklearn_entropy, fn_all_sklearn_entropy, tp_all_sklearn_entropy = cm_all_sklearn.ravel()\n",
    "# flatten the multi-dimensional confusion matrix array into its 4 componenets for binary classificaition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee369c-a69b-47f2-a733-92be6540e0af",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3b6c45d8-2fbe-4fe2-84f9-29f87d003818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here in my confusion matric function we pass in whatever data we want to predict labels for, for us the testing data\n",
    "# and we need the label col name as well as the random forest dicitonary\n",
    "\n",
    "# we then declare our 4 confusioon matrix parameters and for each sample in our testing dataset\n",
    "# we take an aggregate prediciton from the random forest\n",
    "# and then we compare the prediciton to the actual sample class label numerical category / binary classification\n",
    "# given the 4 confusion matrix parameters depending on the outcome of the comparision from the prediction and the correct value we\n",
    "# incremenet the confusion matrix parameter that is associated with the outcome\n",
    "# true positive is true with a true prediciton\n",
    "# false positive is false with a true prediciton\n",
    "# true negative is negative with a negative prediciton\n",
    "# false negative is negative with a npositive prediciton\n",
    "\n",
    "def kelton_confusion_matrix(forest_dict_trees, data, label_column_name):\n",
    "    True_Positive = 0\n",
    "    False_Positive = 0\n",
    "    True_Negative = 0\n",
    "    False_Negative = 0\n",
    "    \n",
    "    for index, sample in data.iterrows():\n",
    "        prediction = aggregate_prediction(forest_dict_trees, sample)\n",
    "        actual_Value = sample[label_column_name]\n",
    "\n",
    "        if prediction == 1 and actual_Value == 1:\n",
    "            True_Positive +=1\n",
    "        elif prediction == 1 and actual_Value == 0:\n",
    "            False_Positive +=1\n",
    "        elif prediction == 0 and actual_Value == 0:\n",
    "            True_Negative +=1\n",
    "        elif prediction == 0 and actual_Value == 1:\n",
    "            False_Negative +=1\n",
    "\n",
    "    return     True_Positive, False_Positive, True_Negative, False_Negative \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bb1b0ff2-e3ad-4fb9-9a09-023be7a5526a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4905, 1890],\n",
       "       [ 254, 1998]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SKLEARN orientation = \n",
    "# tn, fp\n",
    "# fn, tp \n",
    "# but if I am being honest I don't understand why its this orientation as diagnolly swapped seems more \"user/reader\" friendly:\n",
    "# tp, fn\n",
    "# fp, tn\n",
    "\n",
    "# here I display my confusion matrix in the same way that sklearn displays theirs for an apples to apples comparision\n",
    "# TN - FP\n",
    "# FN - TP\n",
    "\n",
    "TP, FP, TN, FN = kelton_confusion_matrix(forest_dict_trees, test_data, label_column_name)\n",
    "confusion_matrix = np.array([[TN, FP], [FN, TP]])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "af050aab-48f6-44b6-bc96-464c5b59df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct classifications / total classifications\n",
    "# true positive + true negative / tp + tn + false pos +false neg\n",
    "# here we take the accuracy of our predicitons, all correct classification divided by the total number of classifications\n",
    "def accuracy_confusion_matrix (TP, FP, TN, FN):\n",
    "    return ((TP+TN) / (TP+TN+FP+FN))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6e539c78-b487-43b7-86d1-38c037cd833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many predicted positive are correct - how many of the predicted positives were actually correct\n",
    "# true positive / tp + false positives\n",
    "# if false positives are important then use this\n",
    "# we compute how many true positives dividied by tp + false positive to calculate our precision for true positives\n",
    "def precision_confusion_matrix (TP, FP, TN, FN):\n",
    "    return ((TP) / (TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0407b09b-45bd-4817-8b88-1b27cbd68118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity - how many actual positives were found - true positives divided by all positives, false negatives are positives\n",
    "# true positive / tp + false negatives\n",
    "# when false negatives are important use this\n",
    "# here we calculate our recal, this is true positives/ tp + false negatives and measures how many of the real positives were correctly guessed\n",
    "def recall_confusion_matrix (TP, FP, TN, FN):\n",
    "    return ((TP) / (TP+FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "89906821-1bf0-4c08-a5f3-7bcbe6ddc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for imbalanced datasets - balance between precision and recall\n",
    "# we use f1score when our datasets are not entirely balanced as datasets with a large amount of samples in one of the label classes\n",
    "# can overly affect our accurcay, precision and recall if the model is overfitted to towards that large imbalance in samples\n",
    "# here we multiple precision and recall then divide that by precision + recall and multiply that result by 2\n",
    "# this \n",
    "def f1_score_confusion_matrix (TP, FP, TN, FN):\n",
    "    precision_correctness = precision_confusion_matrix(TP, FP, TN, FN)\n",
    "    recall_sensitivity = recall_confusion_matrix(TP, FP, TN, FN)\n",
    "    \n",
    "    f1 = 2 * ( (precision_correctness * recall_sensitivity) / (precision_correctness + recall_sensitivity) )\n",
    "    \n",
    "    return f1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae04566-c235-476a-ab92-67e870495662",
   "metadata": {},
   "source": [
    "# Result from my Implementation\n",
    "# I discuss these results in my read me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f0f40746-ea39-444b-b2c8-93460c381133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.30153642091301"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_scratch_accuracy = accuracy_confusion_matrix(TP, FP, TN, FN) \n",
    "from_scratch_accuracy *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "21b3fd89-10d7-40ae-918b-3dd395081b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.388888888888886"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_scratch_precision = precision_confusion_matrix (TP, FP, TN, FN)\n",
    "from_scratch_precision *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4f95002b-4314-4a69-b60f-7a8bd2386f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.72113676731794"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_scratch_recall = recall_confusion_matrix (TP, FP, TN, FN)\n",
    "from_scratch_recall *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eaf1d86a-cd25-45c3-aebb-8fb0421baa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.08143322475568"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_scratch_f1_score =  f1_score_confusion_matrix (TP, FP, TN, FN)\n",
    "from_scratch_f1_score *100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73724b32-420a-4ed3-83d8-fdac12d2c7e4",
   "metadata": {},
   "source": [
    "### Result from my the same data with SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fd617104-c4a0-4885-97ce-1bfa5bb4db83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(85.02265944511993)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_accuracy = accuracy_confusion_matrix(tp_sklearn, fp_sklearn, tn_sklearn, fn_sklearn) \n",
    "sklearn_accuracy *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "429d3e22-d718-4fea-a8e1-8ad80c3d8665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(72.64008076728925)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_precision = precision_confusion_matrix(tp_sklearn, fp_sklearn, tn_sklearn, fn_sklearn) \n",
    "sklearn_precision *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "da0d20d1-7ae5-4163-b7d8-638306e34e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(63.898756660746)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_recall = recall_confusion_matrix(tp_sklearn, fp_sklearn, tn_sklearn, fn_sklearn) \n",
    "sklearn_recall *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3c41bdee-d7b3-4950-b3cb-ca9367cd7192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(67.98960548074652)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_f1_score = f1_score_confusion_matrix(tp_sklearn, fp_sklearn, tn_sklearn, fn_sklearn) \n",
    "sklearn_f1_score *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb47977-51cd-4350-94bf-424f4f581235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48555e1a-39d8-45f1-ac03-3a683d6ca7f6",
   "metadata": {},
   "source": [
    "### Result from the same dataset but with encoding from SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c33f84c9-dcb5-4a0f-8375-ffada9a1c4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(84.9486131064206)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_accuracy = accuracy_confusion_matrix(tp_all_sklearn_entropy, fp_all_sklearn_entropy, tn_all_sklearn_entropy, fn_all_sklearn_entropy) \n",
    "sklearn_accuracy *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb44422f-bea4-4f77-b754-268c60a8e24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(72.81105990783409)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_precision = precision_confusion_matrix(tp_all_sklearn_entropy, fp_all_sklearn_entropy, tn_all_sklearn_entropy, fn_all_sklearn_entropy) \n",
    "sklearn_precision *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d8ebbec4-5682-4801-952b-162cd82ee56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(63.115845539280954)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_recall = recall_confusion_matrix(tp_all_sklearn_entropy, fp_all_sklearn_entropy, tn_all_sklearn_entropy, fn_all_sklearn_entropy) \n",
    "sklearn_recall *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83e6eee3-7455-4be1-9704-b28bb4534751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(67.61768901569187)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_f1_score = f1_score_confusion_matrix(tp_all_sklearn_entropy, fp_all_sklearn_entropy, tn_all_sklearn_entropy, fn_all_sklearn_entropy) \n",
    "sklearn_f1_score *100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a201a7-c0a0-4121-94fc-ab334d97eef1",
   "metadata": {},
   "source": [
    "# Multiprocessing\n",
    "##### I actually broke my laptop while traveling so I did end up with the time to implement multiprocessing like I would have liked to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4e53f32a-5852-4308-b49a-d4a191c3bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcnair_rf_classifier import imported_random_forest_classifier\n",
    "from multiprocessing import Pool # multiprocessing but requires function to be in a .py file when working with jupyter?\n",
    "from multiprocessing import get_context #older fork method not newer spawn, issues with this also, need to put functions in .py file maybe\n",
    "\n",
    "# https://docs.python.org/3.10/library/multiprocessing.html\n",
    "# https://stackoverflow.com/questions/72830743/multiprocessing-changed-in-python-3-9-from-3-7-on-macosx-how-to-fix\n",
    "# https://machinelearningmastery.com/multiprocessing-in-python/\n",
    "# https://medium.com/@dialoglk/boosting-performance-and-efficiency-exploring-the-advantages-of-multiprocessing-in-python-fd48202e1107\n",
    "#\n",
    "\n",
    "# def random_forest_regressor_from_scratch(data, label_column_name, number_of_trees, num_randomized_features, bootstrap_sample_size):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
